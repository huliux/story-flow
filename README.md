# ğŸ“º Story Flow - Intelligent Text-to-Video Generation System

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![uv](https://img.shields.io/badge/uv-package%20manager-blue.svg)](https://github.com/astral-sh/uv)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Version](https://img.shields.io/badge/Version-0.1.0-orange.svg)](https://github.com/story-flow/story-flow)
[![Tests](https://img.shields.io/badge/Tests-Passing-green.svg)](#)
[![Code Quality](https://img.shields.io/badge/Code%20Quality-A+-brightgreen.svg)](#)

**ğŸš€ Transform text into videos, bring stories to life!**

ä¸€ä¸ªå¼ºå¤§çš„AIé©±åŠ¨æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆç³»ç»Ÿï¼Œèƒ½å¤Ÿå°†å°è¯´ã€æ•…äº‹ç­‰æ–‡æœ¬å†…å®¹è‡ªåŠ¨è½¬æ¢ä¸ºåŒ…å«AIç”Ÿæˆå›¾åƒã€çœŸå®è¯­éŸ³åˆæˆå’Œç²¾ç¾å­—å¹•çš„å®Œæ•´è§†é¢‘ä½œå“ã€‚ä½¿ç”¨ç°ä»£åŒ–çš„uvåŒ…ç®¡ç†å™¨ï¼Œæä¾›å¿«é€Ÿã€å¯é çš„ä¾èµ–ç®¡ç†ä½“éªŒã€‚

## ğŸ¬ Demo Videos

https://github.com/user-attachments/assets/4dd1df77-4b7a-4a04-bf7d-d14baaa8955a

https://github.com/user-attachments/assets/a45d2af8-51bb-4db7-a9eb-a546cdafe2dc

*AI-powered automated video generation system designed for content creators*

**ğŸŒ Language:** [English](README.md) | [ä¸­æ–‡](docs/README_CN.md)



</div>

---

## ğŸŒŸ Why Choose Story Flow?

**Story Flow** is a revolutionary AI text-to-video generation system designed to solve content creators' pain points:

- ğŸ“ **Say Goodbye to Tedious Production** - From text to video in one click, save 90% production time
- ğŸ¨ **Professional Visual Effects** - AI-generated high-quality images comparable to professional designers
- ğŸ™ï¸ **Human-like Voice Synthesis** - Azure TTS technology with natural and fluent Chinese speech
- ğŸ¬ **Cinema-quality Video Output** - Automatic subtitles, transition effects, professional video production standards
- ğŸ”§ **Zero Technical Barrier** - Simple configuration, even beginners can create professional video content

## ğŸ¯ Core Advantages

<table>
<tr>
<td width="50%">

### ğŸš€ **Ultra-fast Generation**
- âš¡ **3-minute Generation** - Complete video from 1000 words in 3 minutes
- ğŸ”„ **Batch Processing** - Support multi-chapter parallel processing
- ğŸ“Š **Real-time Progress** - Visual processing progress tracking

### ğŸ¨ **Professional Quality**
- ğŸ–¼ï¸ **4K HD Output** - Support multiple resolutions
- ğŸ­ **Character Consistency** - LoRA models ensure unified character appearance
- ğŸµ **Smart Dubbing** - Multiple voice tones with rich emotions

</td>
<td width="50%">

### ğŸ§  **Intelligent Understanding**
- ğŸ“– **Deep Text Analysis** - AI understands story plots and emotions
- ğŸ‘¥ **Character Recognition** - Automatic identification and management of multiple characters
- ğŸ¬ **Scene Generation** - Intelligently generate visual scenes matching the plot

### ğŸ”§ **Flexible Configuration**
- ğŸ›ï¸ **Adjustable Parameters** - 200+ configuration options for personalized needs
- ğŸ”Œ **Modular Design** - Independent use of functional modules
- ğŸŒ **Multi-service Support** - Support multiple AI service providers

</td>
</tr>
</table>

## âœ¨ Core Features

### ğŸ§  Intelligent Text Analysis
- **Semantic Analysis** - Deep text understanding based on large language models
- **Character Recognition** - Automatic identification and mapping of story characters, support custom character configuration
- **Scene Extraction** - Intelligent extraction of scene descriptions and visual elements
- **Format Support** - Support Markdown, TXT and other input formats
- **Sentence Optimization** - Intelligent merging of short sentences to ensure semantic integrity

### ğŸ¨ Multi-platform Image Generation
- **Stable Diffusion** - Local SD WebUI API support
- **LiblibAI** - Cloud AI painting service integration
- **ComfyUI** - Professional image generation workflow
- **Parallel Processing** - Multi-threaded batch generation, significantly improving efficiency
- **Smart Prompts** - Automatic optimization and style control
- **LoRA Support** - Flexible model fine-tuning and style customization

### ğŸµ Professional Voice Synthesis
- **Azure TTS** - Microsoft Cognitive Services high-quality voice synthesis
- **SSML Support** - Complete Speech Synthesis Markup Language support
- **Multi-dimensional Control** - Precise control of speed, pitch, volume, emotional expression
- **Asynchronous Processing** - Efficient concurrent voice generation
- **Silence Optimization** - Automatic detection and removal of silent segments

### ğŸ¬ Intelligent Video Composition
- **MoviePy Engine** - Professional video processing capabilities
- **Auto Sync** - Intelligent synchronization of images, audio, and subtitles
- **Effects Support** - Multiple visual effects and transition animations
- **Subtitle System** - Automatic generation and style customization
- **Background Music** - Intelligent audio mixing and fade in/out
- **Multi-format Output** - Support multiple video formats and quality options

### ğŸ“š Advanced Features
- **Multi-chapter Processing** - Support chapter-based processing of long content
- **Semantic Analyzer** - Independent story semantic analysis module
- **Viral Video Generation** - Specialized short video content generator
- **Story Generator** - AI-driven original story creation

## ğŸš€ Quick Start

### ğŸ“‹ System Requirements

<table>
<tr>
<td><strong>ğŸ’» Operating System</strong></td>
<td>Windows 10+ / macOS 10.15+ / Ubuntu 18.04+</td>
</tr>
<tr>
<td><strong>ğŸ Python Version</strong></td>
<td>3.10+ (Recommended 3.11)</td>
</tr>
<tr>
<td><strong>ğŸ’¾ Memory Requirements</strong></td>
<td>8GB+ (Recommended 16GB for faster parallel processing)</td>
</tr>
<tr>
<td><strong>ğŸ’¿ Storage Space</strong></td>
<td>5GB+ (Including model files and output cache)</td>
</tr>
<tr>
<td><strong>ğŸŒ Network Requirements</strong></td>
<td>Stable network connection (for AI service calls)</td>
</tr>
<tr>
<td><strong>ğŸ® GPU Support</strong></td>
<td>Optional (NVIDIA GPU can accelerate local Stable Diffusion)</td>
</tr>
</table>

> **ğŸ’¡ Performance Tip**: Higher configuration means faster generation. Recommended configuration can achieve 3-minute generation of 1000-word videos.

### ğŸ› ï¸ Installation Steps

#### 1. Clone Project
```bash
git clone https://github.com/story-flow/story-flow.git
cd story-flow
```

#### 2. Environment Setup
```bash
# Use uv for dependency management (recommended)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Create virtual environment and install dependencies
uv sync

# Activate virtual environment (optional, uv run will auto-activate)
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate  # Windows
```

#### 3. Configure API Services
```bash
# Copy configuration template
cp .env.example .env

# Edit configuration file, fill in your API keys
nano .env  # or use your preferred editor
```

#### 4. Verify Installation
```bash
# Run environment setup script (automatically check and configure environment)
./setup.sh

# Test system connections
uv run python -m tests.examples.test_liblib_config  # Test image generation
uv run python -m src.pipeline.text_analyzer --test  # Test text analysis
```

> **âœ… Installation Success Indicator**: Seeing "âœ“ All systems ready!" indicates successful installation
> 
> **ğŸ”§ Troubleshooting**: If you encounter problems, the script will provide detailed error information and solutions

### ğŸ¬ Three Steps to Start Creating

#### ğŸ¯ **Method 1: One-click Generation (Recommended for beginners)**

```bash
# 1ï¸âƒ£ Prepare content files
cp data/input/input.md.template data/input/input.md
cp data/input/character_mapping.json.template data/input/character_mapping.json

# 2ï¸âƒ£ Prepare story content (choose one of three)
# ğŸ“ Manual editing: Edit data/input/input.md to add story content
# ğŸ‘¥ Configure characters: Edit data/input/character_mapping.json to set character mapping
# ğŸš€ Smart generation: Use viral copywriting generation tool to automatically create content
#   uv run main.py --viral
# ğŸ“– Story generation: Use story generation tool to directly generate stories and automatically configure character recognition
#   uv run main.py --generate

# 3ï¸âƒ£ One-click video generation
uv run main.py --auto
```

#### ğŸ›ï¸ **Method 2: Interactive Generation (Recommended for advanced users)**

```bash
# Launch interactive menu
uv run main.py

# Menu functions:
# ğŸ“Š 1. View system status
# ğŸ¬ 2. Start video generation  
# ğŸ”§ 3. Configure parameters
# ğŸ“ 4. Manage files
# ğŸ§¹ 5. Clean output
```

#### ğŸ“Š **Generation Effect Preview**

| Input Text Length | Estimated Generation Time | Output Video Duration | File Size |
|-------------------|---------------------------|----------------------|----------|
| 500 words | 1-2 minutes | 30-60 seconds | 10-20MB |
| 1000 words | 2-3 minutes | 1-2 minutes | 20-40MB |
| 2000 words | 4-6 minutes | 2-4 minutes | 40-80MB |
| 5000+ words | 10-15 minutes | 5-10 minutes | 100-200MB |

> **âš¡ Performance Optimization**: Using multi-threaded parallel processing, actual speed may be faster

#### ğŸ¬ **Viral Copywriting Smart Generation**

- ğŸ¯ **Theme Customization**: Support any video theme input, AI intelligently understands creative intent
- ğŸ¨ **Style Diversity**: Provide multiple video style choices (warm healing, funny humor, professional serious, etc.)
- ğŸ“Š **Scene Planning**: Intelligently plan video scene count and content structure
- âœ¨ **Prompt Optimization**: Automatically generate high-quality Flux1 image generation prompts
- ğŸš€ **One-click Generation**: From creativity to finished product, full-process automation

```bash
# Launch viral copywriting generator
uv run main.py --viral

# Interactive input:
# ğŸ¯ Video theme (e.g., workplace inspirational story, food making tutorial)
# ğŸ¨ Style hints (e.g., warm healing style, funny humor style)
# ğŸ“Š Scene count (recommended 3-8 scenes)
```

#### ğŸ›ï¸ **Method 2: Interactive Generation (Recommended for advanced users)**

```bash
# Launch interactive menu
uv run main.py --generate

# Menu functions:
# ğŸ“Š 1. View system status
# ğŸ¬ 2. Start video generation  
# ğŸ”§ 3. Configure parameters
# ğŸ“ 4. Manage files
# ğŸ§¹ 5. Clean output
```

#### Method 3: Step-by-step Execution
```bash
# 1. Text analysis and segmentation
uv run python -m src.pipeline.text_analyzer

# 2. Generate images
uv run python -m src.pipeline.image_generator

# 3. Voice synthesis
uv run python -m src.pipeline.voice_synthesizer

# 4. Video composition
uv run python -m src.pipeline.video_composer
```

## ğŸ“š Full Documentation

### ğŸ¯ User Documentation
- **[ğŸ“– User Guide](docs/user-guide.md)** - Complete installation and usage tutorial
- **[ğŸ”§ Environment Setup](docs/environment-setup.md)** - Environment setup and configuration instructions

### ğŸ› ï¸ Development Documentation  
- **[ğŸ—ï¸ Development Guide](docs/development-guide.md)** - Code structure and development instructions
- **[ğŸ“š API Reference](docs/api-reference.md)** - Configuration parameters and interface documentation

## âš™ï¸ Configuration Instructions

### ğŸ”‘ Required API Services

#### 1. Large Language Model (choose one)

**DeepSeek API (Recommended)**
```env
LLM_PROVIDER=deepseek
DEEPSEEK_API_KEY=sk-your-deepseek-key
DEEPSEEK_MODEL=deepseek-chat
```

**OpenAI API**
```env
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-openai-key
OPENAI_MODEL=gpt-3.5-turbo-16k
```

#### 2. Azure Speech Service
```env
AZURE_SPEECH_KEY=your-azure-speech-key
AZURE_SPEECH_REGION=eastasia
AZURE_VOICE_NAME=zh-CN-YunxiNeural
```

#### 3. Image Generation Service (choose one)

**LiblibAI F.1 Model (Recommended)**
```env
# LiblibAI basic configuration
LIBLIB_ACCESS_KEY=your-liblib-access-key
LIBLIB_SECRET_KEY=your-liblib-secret-key
LIBLIB_ENABLED=true

# F.1 model default parameters
F1_DEFAULT_WIDTH=768
F1_DEFAULT_HEIGHT=1024
F1_DEFAULT_STEPS=20
F1_DEFAULT_CFG_SCALE=7.0
F1_DEFAULT_SAMPLER=15
F1_DEFAULT_CLIP_SKIP=2
F1_DEFAULT_TEMPLATE_UUID=6f7c4652458d4802969f8d089cf5b91f
```

**Stable Diffusion API**
```env
SD_API_URL=http://127.0.0.1:7860
SD_STEPS=30
SD_CFG_SCALE=7.5
SD_WIDTH=1360
SD_HEIGHT=1024
```

> **ğŸ’¡ Tip**: F.1 model provides higher quality image generation effects and supports more custom parameters. For detailed configuration, please refer to [F.1 Configuration Guide](docs/f1_configuration_guide.md).

### ğŸ“ Input File Configuration

#### Character Mapping Configuration

First-time use requires creating character mapping configuration file:

```bash
# Copy template file
cp data/input/character_mapping.json.template data/input/character_mapping.json
```

Edit `character_mapping.json` to configure character name replacement and LoRA numbers:

```json
[
  {
    "original_name": "å°é›¨",
    "new_name": "Red-haired Girl",
    "lora_id": "1"
  },
  {
    "original_name": "ç¨‹å®—æ‰¬",
    "new_name": "30-year-old Black-haired Man",
    "lora_id": "2"
  }
]
```

#### Story Content Configuration

```bash
# Copy template file
cp data/input/input.md.template data/input/input.md
```

Then edit the `input.md` file to add your story content. Character names will be automatically replaced according to the above configuration.

### ğŸ›ï¸ Advanced Configuration

<details>
<summary>Click to view complete configuration options</summary>

```env
# Video settings
VIDEO_FPS=24
VIDEO_ENABLE_EFFECT=true
VIDEO_EFFECT_TYPE=fade

# Subtitle settings
SUBTITLE_FONTSIZE=48
SUBTITLE_FONTCOLOR=white
SUBTITLE_STROKE_COLOR=black
SUBTITLE_STROKE_WIDTH=2

# Performance settings
MAX_WORKERS_IMAGE=3
MAX_WORKERS_VIDEO=2
MAX_WORKERS_TRANSLATION=5
```
</details>

ğŸ“– **Detailed Configuration Guide**: [Environment Configuration Documentation](docs/environment-setup.md)

## ğŸ—ï¸ System Architecture

<div align="center">

```mermaid
graph TB
    subgraph "ğŸ“¥ Input Layer"
        A[ğŸ“ Text Content]
        B[ğŸ‘¥ Character Configuration]
        C[âš™ï¸ Generation Parameters]
    end
    
    subgraph "ğŸ§  AI Processing Layer"
        D[ğŸ” Intelligent Text Analysis]
        E[ğŸ“Š Content Understanding & Segmentation]
        F[ğŸ¨ AI Image Generation]
        G[ğŸ™ï¸ Voice Synthesis]
    end
    
    subgraph "ğŸ¬ Composition Layer"
        H[ğŸ–¼ï¸ Image Processing]
        I[ğŸµ Audio Processing]
        J[ğŸ“ Subtitle Generation]
        K[ğŸï¸ Video Composition]
    end
    
    subgraph "ğŸ“¤ Output Layer"
        L[ğŸ“¹ HD Video]
        M[ğŸ“Š Processing Report]
        N[ğŸ“ Resource Files]
    end
    
    A --> D
    B --> D
    C --> D
    D --> E
    E --> F
    E --> G
    F --> H
    G --> I
    E --> J
    H --> K
    I --> K
    J --> K
    K --> L
    K --> M
    K --> N
    
    style A fill:#e1f5fe
    style L fill:#e8f5e8
    style D fill:#fff3e0
    style K fill:#f3e5f5
```

</div>

### ğŸ”„ **Processing Flow Details**

1. **ğŸ“ Intelligent Parsing** - AI deeply understands text content, identifies plots, characters, scenes
2. **ğŸ¨ Visual Generation** - Generate high-quality illustrations based on content descriptions, maintaining character consistency
3. **ğŸ™ï¸ Voice Synthesis** - Convert text to natural and fluent Chinese speech
4. **ğŸ¬ Intelligent Composition** - Automatically synchronize images, audio, subtitles to generate professional videos
5. **ğŸ“¤ Optimized Output** - Multi-format output supporting different platform needs

### ğŸ“ Project Structure

```
story-flow/
â”œâ”€â”€ ğŸ“ src/                           # Core source code
â”‚   â”œâ”€â”€ ğŸ“ pipeline/                  # Processing pipeline modules
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ text_analyzer.py       # Intelligent text analyzer
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ image_generator.py      # Multi-platform image generator
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ voice_synthesizer.py    # Azure TTS voice synthesis
â”‚   â”‚   â””â”€â”€ ğŸ“„ video_composer.py       # MoviePy video composer
â”‚   â”œâ”€â”€ ğŸ“„ config.py                  # Unified configuration management system
â”‚   â”œâ”€â”€ ğŸ“„ llm_client.py             # LLM client (OpenAI/DeepSeek)
â”‚   â”œâ”€â”€ ğŸ“„ semantic_analyzer.py       # Semantic analyzer
â”‚   â”œâ”€â”€ ğŸ“„ story_generator.py         # AI story generator
â”‚   â”œâ”€â”€ ğŸ“„ viral_video_generator.py   # Viral video generator
â”‚   â””â”€â”€ ğŸ“„ image_to_video.py          # Image-to-video module
â”œâ”€â”€ ğŸ“ data/                          # Data directory
â”‚   â”œâ”€â”€ ğŸ“ input/                     # Input files
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ character_mapping.json.template  # Character mapping template
â”‚   â”‚   â””â”€â”€ ğŸ“„ input.md.template               # Story content template
â”‚   â”œâ”€â”€ ğŸ“ output/                    # Output file directory
â”‚   â”‚   â”œâ”€â”€ ğŸ“ txt/                   # Text analysis results (JSON)
â”‚   â”‚   â”œâ”€â”€ ğŸ“ images/                # AI-generated images
â”‚   â”‚   â”œâ”€â”€ ğŸ“ voices/                # TTS voice files
â”‚   â”‚   â”œâ”€â”€ ğŸ“ videos/                # Final video output
â”‚   â”‚   â”œâ”€â”€ ğŸ“ video_clips/           # Video clips
â”‚   â”‚   â””â”€â”€ ğŸ“ temp/                  # Temporary files
â”‚   â””â”€â”€ ğŸ“ processed/                 # Processed CSV files
â”œâ”€â”€ ğŸ“ tests/                         # Test suite
â”‚   â”œâ”€â”€ ğŸ“ unit/                      # Unit tests
â”‚   â”œâ”€â”€ ğŸ“ integration/               # Integration tests
â”‚   â””â”€â”€ ğŸ“ fixtures/                  # Test data
â”œâ”€â”€ ğŸ“ docs/                          # Project documentation
â”‚   â””â”€â”€ ğŸ“„ ç”¨æˆ·æ“ä½œæ•™ç¨‹.md            # Detailed usage tutorial
â”œâ”€â”€ ğŸ“ workflows/                     # ComfyUI workflow configuration
â”œâ”€â”€ ğŸ“„ main.py                        # Main program entry
â”œâ”€â”€ ğŸ“„ pyproject.toml                 # Project configuration and dependencies
â”œâ”€â”€ ğŸ“„ .env.example                   # Environment variable template
â”œâ”€â”€ ğŸ“„ setup.sh                      # Environment setup script
â””â”€â”€ ğŸ“„ cleanup.sh                    # Cleanup script
```

## ğŸ¯ Use Cases

### ğŸ“š Content Creation
- **Story Visualization** - Convert novels, fairy tales and other text content into animated videos
- **Self-media Production** - Quickly generate video content for YouTube, Bilibili and other platforms
- **Audiobooks** - Immersive reading experience combining images and voice

### ğŸ“ Education and Training
- **Course Production** - Convert teaching materials into multimedia courses
- **Knowledge Visualization** - Visual representation of abstract concepts
- **Language Learning** - Audio-visual combined learning of multilingual content

### ğŸ’¼ Business Applications
- **Product Demonstrations** - Quickly generate product introduction and instruction videos
- **Marketing Content** - Video visualization of brand stories and advertising creativity
- **Training Materials** - Corporate training and operation guide videos

### ğŸ“± Social Media
- **Short Video Creation** - Content generation for TikTok, Douyin and other platforms
- **Story Sharing** - Video expression of personal experiences and creative stories
- **Viral Marketing** - Use AI to generate eye-catching creative content

### ğŸš€ Innovative Applications
- **Prototype Validation** - Quickly test video creativity and concepts
- **Personalized Content** - Customized video generation based on user preferences
- **Multilingual Localization** - Multilingual video versions of the same content

## ğŸ”§ Technology Stack

### ğŸ§  AI Service Integration
- **Large Language Models**: OpenAI GPT-4 / DeepSeek Chat
- **Image Generation**: Stable Diffusion WebUI / LiblibAI / ComfyUI
- **Voice Synthesis**: Azure Cognitive Services TTS
- **Semantic Analysis**: Transformer-based text understanding

### ğŸ’» Core Technologies
- **Python 3.10+**: Modern Python feature support
- **Asynchronous Programming**: asyncio high-concurrency processing
- **Parallel Computing**: ThreadPoolExecutor multi-threading optimization
- **MoviePy**: Professional video processing engine
- **PIL/Pillow**: Image processing and effects

### ğŸ“¦ Dependency Management
- **uv**: Modern Python package manager
- **pyproject.toml**: Standardized project configuration
- **python-dotenv**: Environment variable management
- **pydantic**: Data validation and configuration management

### ğŸ”§ Development Tools
- **pytest**: Complete testing framework
- **tqdm**: Progress bars and user experience optimization
- **pathlib**: Modern file path handling
- **logging**: Structured logging system

### ğŸŒ API Integration
- **requests**: HTTP client
- **websocket-client**: WebSocket communication
- **azure-cognitiveservices-speech**: Azure TTS SDK
- **openai**: OpenAI official SDK

<div align="center">

| Technology Domain | Core Technology | Version Requirements | Description |
|-------------------|-----------------|---------------------|-------------|
| **ğŸ Core Language** | Python | 3.10+ | Modern Python feature support |
| **ğŸ“¦ Package Management** | uv | Latest | Ultra-fast dependency management |
| **ğŸ§  AI Large Models** | OpenAI/DeepSeek | API | Intelligent text understanding |
| **ğŸ¨ Image Generation** | Stable Diffusion/F.1 | API | High-quality AI drawing |
| **ğŸ™ï¸ Voice Synthesis** | Azure TTS | API | Human-level Chinese voice |
| **ğŸ¬ Video Processing** | MoviePy | 1.0+ | Professional video editing |
| **ğŸ“Š Data Processing** | Pandas/NumPy | Latest | Efficient data operations |
| **ğŸ–¼ï¸ Image Processing** | Pillow/OpenCV | Latest | Image optimization processing |
| **ğŸµ Audio Processing** | Pydub/librosa | Latest | Audio editing and synthesis |
| **ğŸ§ª Testing Framework** | pytest | Latest | Complete test coverage |

</div>

### ğŸŒŸ **Technical Highlights**

- **âš¡ Asynchronous Processing**: High-concurrency architecture based on asyncio
- **ğŸ”§ Modular Design**: Loosely coupled components, easy to extend and maintain  
- **ğŸ›¡ï¸ Error Recovery**: Comprehensive exception handling and automatic retry mechanisms
- **ğŸ“Š Performance Monitoring**: Built-in performance analysis and resource usage statistics
- **ğŸ”’ Security Assurance**: Encrypted storage of API keys, secure file operations

## ğŸ§¹ Project Maintenance

### Clean Generated Files
```bash
# Run cleanup script (interactive selection of cleanup content)
./cleanup.sh

# Cleanup script functions:
# - Clean generated images and audio files
# - Clean temporary files and cache
# - Organize input files to specified directory
# - Display disk space usage statistics
# - Automatically preserve .gitkeep files and important files in videos directory
```

**ğŸ›¡ï¸ Smart Cleanup Protection:**
- Built-in smart cleanup function automatically cleans temporary files before processing new chapters
- Automatically protect important files: `.gitkeep` files and video files in `videos` directory
- Only clean necessary temporary files (images, audio, CSV), avoid accidentally deleting important content
- Cleanup process errors won't interrupt main flow, ensuring program stability

## ğŸ¤ Contribution Guidelines

We welcome all forms of contributions! Please check the [Contribution Guidelines](CONTRIBUTING.md) for details.

### ğŸ› Issue Feedback

If you encounter problems or have suggestions, please:
1. Check [FAQ](docs/FAQ.md)
2. Search existing [Issues](https://github.com/story-flow/story-flow/issues)
3. Create new Issue with detailed information

### ğŸ“ Development Plan

#### âœ… **Implemented Features** (v0.1.0)

<table>
<tr>
<td width="50%">

**ğŸ¯ Core Functions**
- [x] ğŸ“ Intelligent text analysis and segmentation
- [x] ğŸ¨ AI image generation (SD/F.1)
- [x] ğŸ™ï¸ Intelligent voice synthesis (Azure TTS)
- [x] ğŸ¬ Automatic video composition
- [x] ğŸ‘¥ Multi-character management system
- [x] ğŸ¬ Viral copywriting smart generation

</td>
<td width="50%">

**ğŸ”§ System Features**
- [x] ğŸ“Š Multi-format data support
- [x] ğŸ§ª Complete test coverage (90%+)
- [x] ğŸ§¹ Smart cleanup system
- [x] âš¡ Modern package management (uv)
- [x] ğŸ›¡ï¸ Error recovery mechanism
- [x] ğŸ“ˆ Performance monitoring statistics

</td>
</tr>
</table>

#### ğŸš€ **Development Roadmap** (v0.2.0 - v1.0.0)

**ğŸ¬ Next Version (v0.2.0) - Expected Q2 2024**
- [ ] ğŸï¸ Image-to-video functionality - Runway/Pika AI integration
- [ ] ğŸ™ï¸ GPT-SoVITS voice cloning - Personalized voice customization
- [ ] ğŸ“± JianYing draft generation - One-click import to professional editing software
- [ ] ğŸµ AI music generation - Smart background music configuration

**ğŸŒ Medium-term Planning (v0.5.0) - Expected Q3 2024**
- [ ] ğŸ–¥ï¸ Web interface - Visual operation interface
- [ ] ğŸ³ Docker deployment - One-click containerized deployment
- [ ] ğŸ”„ Real-time preview - Generation process visualization
- [ ] ğŸ“Š Data analysis - Generation effect statistical analysis

#### System Optimization
- [ ] ğŸ¤ More voice service provider support - Expand voice synthesis options
- [ ] ğŸï¸ Video template system - Provide diverse video style templates
- [ ] ğŸ‘€ Real-time preview function - Visual preview of generation process
- [ ] ğŸŒ Web interface development - Provide friendly web operation interface
- [ ] ğŸ³ Docker containerized deployment - Simplify deployment and distribution process
- [ ] âš¡ Performance optimization - Multi-threading processing and caching mechanisms
- [ ] ğŸ”„ Incremental updates - Support partial content updates instead of full regeneration

**ğŸŒŸ Long-term Vision (v1.0.0+) - Q4 2024 and beyond**
- [ ] ğŸ¤– AI Agent system - Fully automated content creation agents
- [ ] ğŸ”¥ Hot content conversion - Automatically capture network hotspots to generate videos
- [ ] ğŸ¯ Personalized recommendations - Smart recommendations based on user preferences
- [ ] ğŸŒ Multi-language support - Global content creation platform
- [ ] ğŸ¢ Enterprise features - Team collaboration, permission management, API services

> **ğŸ“ˆ Development Goal**: Become the world's leading AI video generation platform, serving millions of content creators

## ğŸ“ Contact

If you encounter problems during use or have any suggestions, please contact us through the following methods:

### ğŸ› Issue Feedback
- **GitHub Issues**: [Submit Bug Reports or Feature Requests](https://github.com/story-flow/story-flow/issues)
- **Issue Templates**: Please use corresponding Issue templates, provide detailed problem descriptions and reproduction steps

### ğŸ’¬ Communication and Discussion
- **GitHub Discussions**: [Participate in Project Discussions](https://github.com/story-flow/story-flow/discussions)
- **Feature Suggestions**: Share your ideas and suggestions in Discussions
- **Usage Experience**: Share your usage insights and best practices

### ğŸ“§ Direct Contact
- **Project Maintainer**: [dasenrising@gmail.com](mailto:dasenrising@gmail.com)
- **Technical Support**: [dasenrising@gmail.com](mailto:dasenrising@gmail.com)
- **Business Cooperation**: [dasenrising@gmail.com](mailto:dasenrising@gmail.com)

### ğŸŒ Social Media
- **WeChat Group**: Scan the QR code below to join the communication group

<div align="center">
  <img src="docs/images/WechatIMG1343.png" alt="WeChat Group QR Code" width="200"/>
  <p><em>ğŸ¯ Scan to join Story Flow Creator Community</em></p>
  <p><strong>ğŸ’¬ 1000+ Creators â€¢ ğŸ“š Experience Sharing â€¢ ğŸ”§ Technical Support â€¢ ğŸ Exclusive Resources</strong></p>
</div>

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE) - see the LICENSE file for details.

## ğŸ™ Acknowledgments

Thanks to the following open source projects and services:
- [OpenAI](https://openai.com/) - GPT model services
- [DeepSeek](https://www.deepseek.com/) - Cost-effective LLM services
- [Azure Cognitive Services](https://azure.microsoft.com/services/cognitive-services/) - Speech synthesis services
- [Stable Diffusion](https://stability.ai/) - AI image generation
- [MoviePy](https://zulko.github.io/moviepy/) - Video processing library
- [uv](https://github.com/astral-sh/uv) - Modern Python package manager

---

<div align="center">

## ğŸŒŸ **Support Project Development**

If Story Flow helps you create amazing content, please consider supporting us:

[![GitHub stars](https://img.shields.io/github/stars/story-flow/story-flow?style=social)](https://github.com/story-flow/story-flow/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/story-flow/story-flow?style=social)](https://github.com/story-flow/story-flow/network)
[![GitHub watchers](https://img.shields.io/github/watchers/story-flow/story-flow?style=social)](https://github.com/story-flow/story-flow/watchers)

**â­ Give us a Star** â€¢ **ğŸ”„ Share with Friends** â€¢ **ğŸ’¬ Join Discussions** â€¢ **ğŸ› Report Issues**

---

### ğŸ“š **Quick Navigation**

[ğŸ  Project Home](https://github.com/story-flow/story-flow) â€¢ [ğŸ“– Documentation](docs/) â€¢ [ğŸ¬ Video Tutorials](#) â€¢ [ğŸ’¬ Community Discussions](https://github.com/story-flow/story-flow/discussions)

[ğŸ› Issue Feedback](https://github.com/story-flow/story-flow/issues) â€¢ [ğŸ’¡ Feature Suggestions](https://github.com/story-flow/story-flow/discussions/categories/ideas) â€¢ [ğŸ¤ Contribute](CONTRIBUTING.md) â€¢ [ğŸ“„ Changelog](CHANGELOG.md)

---

**ğŸ’ Empowering everyone to become an excellent content creator**

*Story Flow - Illuminate creativity with AI* âœ¨

</div>