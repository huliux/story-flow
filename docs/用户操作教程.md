# Story Flow 用户操作教程

## 📖 教程概述

本教程将详细介绍 Story Flow AI文本到视频生成系统的使用方法，帮助您快速掌握从文本创作到视频生成的完整流程。本教程专注于业务功能的使用，不涉及环境搭建和开发细节。

## 🎯 Story Flow 项目介绍

### 什么是 Story Flow？

Story Flow 是一个强大的AI驱动文本到视频生成系统，能够将小说、故事等文本内容自动转换为包含AI生成图像、真实语音合成和精美字幕的完整视频作品。

### 🌟 核心价值

- **🤖 全自动化流水线** - 一键从文本生成完整视频，无需手动干预
- **🧠 多AI模型集成** - 集成OpenAI GPT、DeepSeek、Stable Diffusion、Azure TTS等先进AI服务
- **🎨 高质量视觉效果** - 专业级视频输出，支持多种风格和特效
- **🔧 高度可配置** - 灵活的参数调整，满足不同创作需求
- **📱 用户友好** - 简单易用的操作界面，适合各种技能水平的用户

### 🎬 主要功能特性

#### 1. 智能文本处理
- **AI故事生成** - 根据主题自动创作完整故事
- **多LLM支持** - 支持OpenAI GPT-3.5/4和DeepSeek等大语言模型
- **智能分段** - 自动识别章节和段落结构
- **内容分析** - AI理解文本内容并生成视觉描述
- **角色名替换** - 支持自定义角色名和LoRA模型映射
- **多语言支持** - 支持中英文内容处理

#### 2. AI图像生成
- **Stable Diffusion集成** - 高质量AI图像生成
- **LoRA模型支持** - 风格化图像定制，支持特定角色和风格
- **批量处理** - 多线程并发生成，提高效率
- **参数可调** - 丰富的生成参数配置，控制图像质量和风格

#### 3. 语音合成
- **Azure TTS** - 微软认知服务语音合成
- **多种音色** - 支持多种中文语音角色
- **情感表达** - 可配置语音风格和情感
- **高质量输出** - 自然流畅的语音效果

#### 4. 视频制作
- **自动合成** - 图像、语音、字幕自动合成
- **专业字幕** - 可自定义字体、颜色、位置
- **视觉特效** - 支持多种视频转场效果
- **高清输出** - 支持多种分辨率和格式

#### 5. 多章节处理
- **章节识别** - 自动识别和解析多章节内容
- **顺序处理** - 按章节顺序依次处理，避免内容混乱
- **智能清理** - 每章节处理前自动清理上一章节的输出文件
- **进度跟踪** - 实时显示章节处理进度和状态
- **文件保护** - 自动保留重要文件，避免误删

### 🎯 应用场景

#### 内容创作领域
- **📚 小说可视化** - 将小说章节转换为视频，增强阅读体验
- **🎓 教育内容** - 制作教学视频和课件，提高教学效果
- **📖 故事讲述** - 儿童故事、寓言等的视频化呈现
- **🎬 内容创作** - 自媒体视频制作，快速产出优质内容
- **📱 社交媒体** - 短视频内容生成，适合各种平台

#### 商业应用
- **营销推广** - 产品故事视频制作
- **企业培训** - 培训材料视频化
- **品牌宣传** - 品牌故事视频制作

#### 个人创作
- **创意表达** - 个人创意和想法的视频化
- **记录分享** - 生活故事的视频记录
- **学习辅助** - 学习内容的视频化整理

### 🔄 工作流程概览

Story Flow 的完整工作流程包括以下步骤：

1. **📝 文本输入/生成** - 输入现有故事或使用AI生成新故事
2. **🔍 文本分析** - AI分析文本内容，生成章节结构和视觉描述
3. **📊 故事板生成** - 创建详细的故事板CSV文件
4. **🎨 图像生成** - 根据故事板生成对应的AI图像
5. **🎙️ 语音合成** - 将文本转换为自然语音
6. **🎬 视频合成** - 将图像、音频和字幕合成为最终视频

每个步骤都可以单独执行，也可以通过自动化流水线一键完成全部流程。

---

## 📋 使用前准备

在开始使用 Story Flow 之前，请确保您已经完成了环境搭建和基本配置。如果还没有完成，请参考项目的安装文档。

### 必需的配置文件

使用 Story Flow 需要准备以下配置文件：

1. **环境配置文件** (`.env`) - 包含API密钥和服务配置
2. **角色映射文件** (`character_mapping.json`) - 定义角色名替换和LoRA模型
3. **输入文件** (`input.md`) - 故事内容或由AI生成

接下来的章节将详细介绍如何配置和使用这些功能。

---

## ⚙️ 配置管理

### 1. 环境配置 (.env)

环境配置文件包含了所有必需的API密钥和服务配置。请在项目根目录创建 `.env` 文件：

⚠️ **安全提醒**：
- `.env` 文件包含敏感信息，请确保已添加到 `.gitignore` 中
- 不要将包含真实密钥的 `.env` 文件提交到版本控制系统
- 定期检查和轮换API密钥
- 使用环境变量管理工具（如 `python-decouple`）来安全地加载配置

```bash
# OpenAI API 配置
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_BASE_URL=https://api.openai.com/v1  # 可选，默认官方API

# DeepSeek API 配置（可选）
DEEPSEEK_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1

# Stable Diffusion API 配置
SD_API_BASE_URL=http://127.0.0.1:7860  # 本地SD WebUI地址
# 或使用云端服务
# SD_API_BASE_URL=https://your-sd-service.com

# Azure 语音服务配置
AZURE_SPEECH_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
AZURE_SPEECH_REGION=eastus  # 如：eastus, westus2

# 可选配置
LOG_LEVEL=INFO  # 日志级别：DEBUG, INFO, WARNING, ERROR
MAX_WORKERS=4   # 并发处理线程数
```

#### 🔑 API密钥获取指南

**OpenAI API**
1. 访问 [OpenAI Platform](https://platform.openai.com/)
2. 注册账号并完成验证
3. 在 API Keys 页面创建新的API密钥
4. 确保账户有足够的余额
5. **重要**：妥善保管API密钥，不要在代码中硬编码或公开分享

**DeepSeek API**（可选）
1. 访问 [DeepSeek Platform](https://platform.deepseek.com/)
2. 注册账号并获取API密钥
3. 相比OpenAI更经济实惠
4. **注意**：同样需要妥善保管密钥

**Azure 语音服务**
1. 访问 [Azure Portal](https://portal.azure.com/)
2. 创建「语音服务」资源
3. 获取密钥和区域信息
4. 免费层每月提供50万字符额度
5. **安全提醒**：定期轮换密钥，监控使用情况

**Stable Diffusion**
- **本地部署**：安装 [AUTOMATIC1111 WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
- **云端服务**：使用 Replicate、RunPod 等云端SD服务

### 2. 角色映射配置 (character_mapping.json)

角色映射文件用于自定义角色名称和对应的LoRA模型，实现角色一致性的图像生成。

#### 📝 配置文件结构

```json
{
  "角色名1": {
    "lora_model": "lora_model_name",
    "lora_weight": 0.8,
    "replacement_name": "替换后的角色名",
    "description": "角色描述"
  },
  "角色名2": {
    "lora_model": "another_lora_model",
    "lora_weight": 0.7,
    "replacement_name": "另一个角色名",
    "description": "另一个角色的描述"
  }
}
```

#### 🎭 配置示例

```json
{
  "小明": {
    "lora_model": "boy_character_v1",
    "lora_weight": 0.8,
    "replacement_name": "Alex",
    "description": "一个聪明活泼的男孩"
  },
  "小红": {
    "lora_model": "girl_character_v2",
    "lora_weight": 0.7,
    "replacement_name": "Emma",
    "description": "一个温柔善良的女孩"
  },
  "老师": {
    "lora_model": "teacher_model",
    "lora_weight": 0.6,
    "replacement_name": "Mr. Johnson",
    "description": "一位经验丰富的教师"
  }
}
```

#### 🔧 参数说明

- **lora_model**: LoRA模型名称，需要在SD WebUI中已安装
- **lora_weight**: LoRA权重，范围0.1-1.0，控制风格强度
- **replacement_name**: 替换后的角色名，用于图像生成提示词
- **description**: 角色描述，帮助生成更准确的图像

#### 💡 使用技巧

1. **LoRA模型选择**：选择与角色特征匹配的LoRA模型
2. **权重调节**：较高权重(0.8-1.0)风格更明显，较低权重(0.4-0.6)更自然
3. **名称替换**：使用英文名称通常能获得更好的图像生成效果
4. **描述优化**：详细的角色描述有助于生成一致性更好的图像

### 3. 输入文件准备 (input.md)

输入文件是故事内容的载体，支持Markdown格式，可以手动编写或使用AI生成。

#### 📄 文件格式要求

```markdown
# 故事标题

## 第一章 章节标题

这里是第一章的内容。可以包含对话、描述、动作等。

"你好，世界！"小明兴奋地说道。

小红微笑着回应："你好，小明！"

## 第二章 另一个章节

继续故事的发展...
```

#### 📋 格式规范

1. **章节标识**：使用 `## 第X章` 或 `## Chapter X` 格式
2. **对话格式**：使用引号包围对话内容
3. **角色名称**：确保角色名与 `character_mapping.json` 中的配置一致
4. **段落分隔**：使用空行分隔不同段落
5. **特殊标记**：可以使用 `**粗体**` 和 `*斜体*` 等Markdown格式

#### 💡 内容编写建议

1. **场景描述**：详细描述场景环境，有助于生成准确的背景图像
2. **角色动作**：明确描述角色的动作和表情
3. **情感表达**：通过对话和描述传达角色情感
4. **节奏控制**：合理安排情节发展节奏
5. **视觉元素**：多使用具有视觉冲击力的描述

#### 🎯 优化技巧

- **长度控制**：每个段落建议50-200字，便于语音合成和视频节奏
- **对话平衡**：对话和叙述保持适当比例
- **场景变化**：适当的场景转换增加视觉丰富性
- **角色一致性**：保持角色性格和行为的一致性

---

## 🤖 AI故事生成功能

Story Flow 内置强大的AI故事生成功能，可以根据您提供的主题自动创作完整的故事内容。这个功能特别适合需要快速创作内容或寻找创作灵感的用户。

### 🚀 启动AI故事生成

#### 方法一：交互式菜单启动

1. **启动程序**
   ```bash
   uv run main.py
   ```

2. **选择故事生成选项**
   ```
   ========================================
   Story Flow - AI文本到视频生成系统
   ========================================
   
   请选择操作：
   1. 自动运行完整流水线
   2. 生成新故事 (AI创作)  ← 选择此项
   3. 分割文本为章节
   4. 生成故事板
   5. 生成图像
   6. 生成音频
   7. 生成视频
   8. 退出
   
   请输入选项 (1-8): 2
   ```

#### 方法二：命令行直接启动

```bash
# 直接启动故事生成模块
uv run main.py --module story_generator

# 或使用简写
uv run main.py -m story_generator
```

### 📝 故事主题输入

启动故事生成功能后，系统会提示您输入故事主题：

```
请输入故事主题或概要（按回车确认）:
> 一个关于友谊和冒险的童话故事
```

#### 💡 主题输入技巧

**优秀主题示例：**
- "一个关于勇敢小女孩拯救森林的环保故事"
- "两个好朋友在神秘图书馆中的奇幻冒险"
- "一只会说话的猫咪帮助主人找回自信的温馨故事"
- "未来世界中机器人与人类和谐共处的科幻故事"

**主题描述建议：**
1. **明确主角**：指定主要角色的特征
2. **设定背景**：描述故事发生的环境或时代
3. **核心冲突**：简述故事的主要矛盾或挑战
4. **情感基调**：表明故事的情感色彩（温馨、冒险、悬疑等）
5. **目标受众**：考虑故事适合的年龄群体

**避免的主题类型：**
- 过于抽象或哲学性的主题
- 包含暴力、恐怖或不适宜内容的主题
- 过于复杂或需要大量背景知识的主题

### 🎯 AI生成过程

输入主题后，AI将开始生成故事：

```
正在生成故事，请稍候...
使用模型: gpt-3.5-turbo
主题: 一个关于友谊和冒险的童话故事

[████████████████████████████████] 100%

故事生成完成！
故事已保存到: data/input/input.md
故事长度: 1,234 字
章节数量: 3 章
```

#### 🔄 生成参数说明

系统会根据以下参数生成故事：

- **模型选择**：优先使用 DeepSeek（如已配置），否则使用 OpenAI GPT
- **故事长度**：通常生成 800-2000 字的中篇故事
- **章节结构**：自动分为 2-5 个章节
- **角色设定**：根据主题自动创建合适的角色
- **情节发展**：包含开端、发展、高潮、结局的完整结构

### 📁 文件管理

#### 🔍 生成文件位置

故事生成完成后，文件将保存在以下位置：

```
data/input/
├── input.md          # 新生成的故事内容
├── backup/           # 备份文件夹
│   └── input_YYYYMMDD_HHMMSS.md  # 之前的故事备份
```

#### 💾 自动备份机制

**备份规则：**
1. 如果 `input.md` 已存在，系统会自动创建备份
2. 备份文件名格式：`input_20250119_143022.md`
3. 备份文件保存在 `data/input/backup/` 目录
4. 系统会保留所有历史备份，不会自动删除

**手动备份：**
```bash
# 手动备份当前故事
cp data/input/input.md data/input/backup/input_$(date +%Y%m%d_%H%M%S).md
```

#### 📖 查看生成的故事

**使用文本编辑器：**
```bash
# 使用默认编辑器打开
open data/input/input.md

# 或使用特定编辑器
code data/input/input.md    # VS Code
vim data/input/input.md     # Vim
nano data/input/input.md    # Nano
```

**预览故事内容：**
```bash
# 查看故事开头
head -20 data/input/input.md

# 查看完整内容
cat data/input/input.md
```

### 🔄 重新生成故事

如果对生成的故事不满意，可以重新生成：

1. **重新运行生成命令**
   ```bash
   uv run main.py --module story_generator
   ```

2. **输入新的主题或相同主题**
   - 相同主题可能产生不同的故事版本
   - 可以尝试更具体或更抽象的主题描述

3. **系统会自动备份之前的版本**

### ⚠️ 注意事项

#### 🔑 API使用
- **费用控制**：AI生成会消耗API调用额度，请注意费用
- **网络要求**：需要稳定的网络连接
- **响应时间**：生成过程通常需要 30-60 秒

#### 📝 内容质量
- **人工审核**：建议对生成的内容进行人工审核和编辑
- **角色一致性**：检查角色名称是否与 `character_mapping.json` 匹配
- **情节连贯性**：确保故事情节逻辑合理

#### 🛠️ 故障排除

**常见问题：**

1. **API密钥错误**
   ```
   错误: OpenAI API key not found
   解决: 检查 .env 文件中的 OPENAI_API_KEY 配置
   ```

2. **网络连接问题**
   ```
   错误: Connection timeout
   解决: 检查网络连接，或尝试使用代理
   ```

3. **生成内容为空**
   ```
   解决: 尝试更具体的主题描述，或检查API余额
   ```

4. **文件权限问题**
   ```
   错误: Permission denied
   解决: 检查 data/input/ 目录的写入权限
   ```

---

## 🔄 完整流水线操作

Story Flow 的核心功能是完整的文本到视频生成流水线。您可以选择自动模式一键完成所有步骤，或者分步执行每个模块以获得更精细的控制。

### 🚀 自动模式（推荐）

自动模式是最简单的使用方式，系统会自动执行所有必要的步骤，从文本分析到最终视频生成。

#### 📋 使用前检查

在启动自动模式前，请确保：

✅ **配置文件完整**
- `.env` 文件包含所有必需的API密钥
- `character_mapping.json` 已配置（如需角色映射）

✅ **输入文件准备**
- `data/input/input.md` 文件存在且包含故事内容
- 文件格式符合要求（Markdown格式，包含章节标识）

✅ **服务状态**
- Stable Diffusion WebUI 正在运行（如使用本地SD）
- 网络连接正常

#### 🎬 启动自动模式

**方法一：交互式菜单**

1. 启动程序：
   ```bash
   uv run main.py
   ```

2. 选择自动模式：
   ```
   请选择操作：
   1. 自动运行完整流水线  ← 选择此项
   2. 生成新故事 (AI创作)
   3. 分割文本为章节
   ...
   
   请输入选项 (1-8): 1
   ```

**方法二：命令行直接启动**

```bash
# 启动完整自动流水线
uv run main.py --auto

# 或使用完整参数名
uv run main.py --auto-run
```

#### 📊 执行过程监控

自动模式启动后，系统会显示详细的执行进度：

```
========================================
Story Flow - 自动流水线执行
========================================

📖 步骤 1/5: 文本分析
正在分析输入文件: data/input/input.md
检测到章节数量: 3
[████████████████████████████████] 100% 完成

📊 步骤 2/5: 生成故事板
正在生成故事板...
使用模型: gpt-3.5-turbo
[████████████████████████████████] 100% 完成
生成故事板条目: 15 个

🎨 步骤 3/5: 生成图像
正在生成图像 (1/15): 森林中的小屋
正在生成图像 (2/15): 勇敢的小女孩
...
[████████████████████████████████] 100% 完成
成功生成图像: 15/15

🎙️ 步骤 4/5: 生成语音
正在合成语音: 第1章
正在合成语音: 第2章
...
[████████████████████████████████] 100% 完成

🎬 步骤 5/5: 生成视频
正在合成视频: 第1章
正在合成视频: 第2章
...
[████████████████████████████████] 100% 完成

✅ 流水线执行完成！
总耗时: 15分32秒
输出文件位置: data/output/
```

#### 🎯 执行结果

自动模式完成后，您将获得以下输出文件：

```
data/output/
├── chapters/                    # 章节文件
│   ├── chapter_1.md
│   ├── chapter_2.md
│   └── chapter_3.md
├── storyboard.csv              # 故事板文件
├── images/                     # 生成的图像
│   ├── image_001.png
│   ├── image_002.png
│   └── ...
├── audio/                      # 语音文件
│   ├── chapter_1.wav
│   ├── chapter_2.wav
│   └── chapter_3.wav
└── videos/                     # 最终视频
    ├── chapter_1.mp4
    ├── chapter_2.mp4
    ├── chapter_3.mp4
    └── final_video.mp4         # 合并后的完整视频
```

### 🔧 分步执行模式

分步执行模式允许您单独运行每个模块，适合需要精细控制或调试的场景。

#### 📝 步骤1：文本分析

**功能说明：**
- 解析 `input.md` 文件
- 识别章节结构
- 分割文本为独立章节文件

**执行方法：**
```bash
# 交互式菜单选择选项3
uv run main.py

# 或命令行直接执行
uv run main.py --module text_analyzer
uv run main.py -m text_analyzer
```

**输出结果：**
```
data/output/chapters/
├── chapter_1.md
├── chapter_2.md
└── chapter_3.md
```

#### 📊 步骤2：生成故事板

**功能说明：**
- 分析章节内容
- 生成详细的视觉描述
- 创建故事板CSV文件

**执行方法：**
```bash
# 交互式菜单选择选项4
uv run main.py

# 或命令行直接执行
uv run main.py --module storyboard_generator
uv run main.py -m storyboard_generator
```

**输出结果：**
```
data/output/storyboard.csv
```

**故事板文件格式：**
```csv
chapter,scene_number,text,image_prompt,character_info
1,1,"小红帽走在森林小径上","A little girl in red hood walking on forest path, fairy tale style","小红帽:little_girl_lora"
1,2,"她遇到了大灰狼","A big gray wolf in the forest, menacing but cartoon style","大灰狼:wolf_character"
```

#### 🎨 步骤3：生成图像

**功能说明：**
- 根据故事板生成AI图像
- 应用角色映射和LoRA模型
- 支持批量并发生成

**执行方法：**
```bash
# 交互式菜单选择选项5
uv run main.py

# 或命令行直接执行
uv run main.py --module image_generator
uv run main.py -m image_generator
```

**生成过程：**
```
🎨 图像生成进度:
[1/15] 正在生成: 森林小径上的小红帽
[2/15] 正在生成: 森林中的大灰狼
[3/15] 正在生成: 奶奶的小屋
...
✅ 图像生成完成: 15/15 成功
```

**输出结果：**
```
data/output/images/
├── image_001.png
├── image_002.png
├── image_003.png
└── ...
```

#### 🎙️ 步骤4：生成语音

**功能说明：**
- 将章节文本转换为语音
- 使用Azure TTS服务
- 支持多种中文语音角色

**执行方法：**
```bash
# 交互式菜单选择选项6
uv run main.py

# 或命令行直接执行
uv run main.py --module voice_synthesizer
uv run main.py -m voice_synthesizer
```

**生成过程：**
```
🎙️ 语音合成进度:
正在合成: 第1章 (1,234 字符)
正在合成: 第2章 (987 字符)
正在合成: 第3章 (1,456 字符)
✅ 语音合成完成
```

**输出结果：**
```
data/output/audio/
├── chapter_1.wav
├── chapter_2.wav
└── chapter_3.wav
```

#### 🎬 步骤5：生成视频

**功能说明：**
- 合成图像、音频和字幕
- 生成章节视频和完整视频
- 支持多种视频格式和分辨率

**执行方法：**
```bash
# 交互式菜单选择选项7
uv run main.py

# 或命令行直接执行
uv run main.py --module video_composer
uv run main.py -m video_composer
```

**生成过程：**
```
🎬 视频合成进度:
正在合成: 第1章视频
  - 添加图像序列
  - 添加背景音频
  - 生成字幕轨道
正在合成: 第2章视频
...
正在合并最终视频
✅ 视频生成完成
```

**输出结果：**
```
data/output/videos/
├── chapter_1.mp4
├── chapter_2.mp4
├── chapter_3.mp4
└── final_video.mp4
```

### ⚡ 执行模式对比

| 特性 | 自动模式 | 分步执行模式 |
|------|----------|-------------|
| **易用性** | ⭐⭐⭐⭐⭐ 一键完成 | ⭐⭐⭐ 需要逐步操作 |
| **控制精度** | ⭐⭐ 有限控制 | ⭐⭐⭐⭐⭐ 完全控制 |
| **调试能力** | ⭐⭐ 难以定位问题 | ⭐⭐⭐⭐⭐ 易于调试 |
| **时间效率** | ⭐⭐⭐⭐⭐ 最快 | ⭐⭐⭐ 需要手动操作 |
| **适用场景** | 日常使用、批量处理 | 开发调试、精细调优 |

### 💡 使用建议

**选择自动模式的情况：**
- 首次使用，配置已完成
- 批量处理多个故事
- 对结果质量要求不高
- 希望快速获得结果

**选择分步执行的情况：**
- 需要调试特定步骤
- 对某个环节有特殊要求
- 想要了解每步的详细过程
- 需要在中间步骤进行人工干预

---

## 🔧 模块详细使用指南

本章节详细介绍每个模块的独立使用方法、参数配置和优化技巧。适合需要精细控制或深度定制的用户。

### 📝 文本分析模块 (Text Analyzer)

文本分析模块负责解析输入的Markdown文件，识别章节结构，并将内容分割为独立的章节文件。

#### 🎯 主要功能

- **章节识别**：自动识别 `## 第X章` 或 `## Chapter X` 格式的章节标题
- **内容分割**：将长文本按章节分割为独立文件
- **格式清理**：清理多余的空行和格式问题
- **元数据提取**：提取章节标题、字数统计等信息

#### 🚀 使用方法

```bash
# 命令行执行
uv run main.py --module text_analyzer

# 或使用简写
uv run main.py -m text_analyzer
```

#### ⚙️ 配置参数

文本分析模块的配置位于 `src/config.py` 中：

```python
# 章节识别模式
CHAPTER_PATTERNS = [
    r'^##\s*第[\d一二三四五六七八九十]+章',  # 中文章节
    r'^##\s*Chapter\s+\d+',                # 英文章节
    r'^##\s*第[\d]+节',                    # 节标识
]

# 最小章节长度（字符数）
MIN_CHAPTER_LENGTH = 50

# 输出目录
CHAPTERS_OUTPUT_DIR = "data/output/chapters"
```

#### 📊 输出结果

执行完成后，会在 `data/output/chapters/` 目录生成以下文件：

```
chapters/
├── chapter_1.md      # 第一章内容
├── chapter_2.md      # 第二章内容
├── chapter_3.md      # 第三章内容
└── metadata.json     # 章节元数据
```

**metadata.json 示例：**
```json
{
  "total_chapters": 3,
  "chapters": [
    {
      "id": 1,
      "title": "第一章 森林的秘密",
      "word_count": 456,
      "file_path": "chapter_1.md"
    },
    {
      "id": 2,
      "title": "第二章 勇敢的冒险",
      "word_count": 523,
      "file_path": "chapter_2.md"
    }
  ]
}
```

### 📊 故事板生成模块 (Storyboard Generator)

故事板生成模块使用AI分析章节内容，生成详细的视觉描述和场景信息。

#### 🎯 主要功能

- **场景分析**：AI理解文本内容，识别关键场景
- **视觉描述**：生成适合图像生成的英文提示词
- **角色映射**：应用角色映射配置，替换角色名称
- **CSV输出**：生成结构化的故事板文件

#### 🚀 使用方法

```bash
# 命令行执行
uv run main.py --module storyboard_generator

# 或使用简写
uv run main.py -m storyboard_generator
```

#### ⚙️ 配置参数

```python
# AI模型配置
STORYBOARD_MODEL = "gpt-3.5-turbo"  # 或 "deepseek-chat"
MAX_SCENES_PER_CHAPTER = 10         # 每章最大场景数
SCENE_DESCRIPTION_LENGTH = 200      # 场景描述最大长度

# 提示词模板
STORYBOARD_PROMPT_TEMPLATE = """
分析以下章节内容，生成视觉场景描述：

章节内容：{chapter_content}

要求：
1. 识别3-8个关键视觉场景
2. 为每个场景生成英文图像提示词
3. 标注出现的角色
4. 描述场景的视觉元素
"""
```

#### 📊 输出结果

生成的 `storyboard.csv` 文件格式：

```csv
chapter,scene_number,text,image_prompt,character_info,duration
1,1,"小红帽走在森林小径上，阳光透过树叶洒下斑驳的光影。","A little girl in red hood walking on a forest path, sunlight filtering through leaves, fairy tale style, warm lighting","小红帽:little_girl_lora:0.8",5.0
1,2,"她遇到了一只看起来友善的大灰狼。","A big gray wolf with friendly expression in the forest, cartoon style, not scary","大灰狼:wolf_character:0.7",4.0
2,1,"小红帽来到了奶奶的小屋前。","A cozy cottage in the forest with flower garden, fairy tale architecture","",3.0
```

**字段说明：**
- `chapter`: 章节编号
- `scene_number`: 场景编号
- `text`: 原文描述
- `image_prompt`: 英文图像生成提示词
- `character_info`: 角色信息（格式：角色名:LoRA模型:权重）
- `duration`: 建议显示时长（秒）

### 🎨 图像生成模块 (Image Generator)

图像生成模块根据故事板文件，使用Stable Diffusion生成高质量的AI图像。

#### 🎯 主要功能

- **批量生成**：根据故事板批量生成图像
- **LoRA支持**：应用角色LoRA模型，保持角色一致性
- **并发处理**：多线程并发生成，提高效率
- **质量控制**：支持多种生成参数调节

#### 🚀 使用方法

```bash
# 命令行执行
uv run main.py --module image_generator

# 或使用简写
uv run main.py -m image_generator
```

#### ⚙️ 配置参数

```python
# Stable Diffusion 配置
SD_API_BASE_URL = "http://127.0.0.1:7860"  # SD WebUI地址
SD_MODEL = "sd_xl_base_1.0.safetensors"    # 使用的模型

# 生成参数
IMAGE_WIDTH = 1024                         # 图像宽度
IMAGE_HEIGHT = 768                         # 图像高度
SAMPLING_STEPS = 20                        # 采样步数
CFG_SCALE = 7.0                           # CFG引导强度
SAMPLER_NAME = "DPM++ 2M Karras"          # 采样器

# 并发设置
MAX_CONCURRENT_IMAGES = 3                  # 最大并发数
IMAGE_GENERATION_TIMEOUT = 120             # 超时时间（秒）

# 质量控制
NEGATIVE_PROMPT = "low quality, blurry, distorted, ugly, bad anatomy"
ENABLE_UPSCALING = True                    # 启用放大
UPSCALE_FACTOR = 2                         # 放大倍数
```

#### 🎨 高级参数调优

**提示词优化：**
```python
# 基础提示词模板
BASE_PROMPT_TEMPLATE = "{scene_prompt}, high quality, detailed, masterpiece, best quality"

# 风格提示词
STYLE_PROMPTS = {
    "fairy_tale": "fairy tale style, storybook illustration, whimsical",
    "realistic": "photorealistic, cinematic lighting, detailed",
    "anime": "anime style, manga, cel shading",
    "cartoon": "cartoon style, colorful, friendly"
}

# 负面提示词
NEGATIVE_PROMPTS = {
    "quality": "low quality, blurry, distorted, ugly",
    "anatomy": "bad anatomy, extra limbs, malformed",
    "style": "realistic, photograph" # 用于卡通风格
}
```

**LoRA配置优化：**
```json
{
  "小红帽": {
    "lora_model": "little_red_riding_hood_v2",
    "lora_weight": 0.8,
    "trigger_words": ["red hood", "little girl"],
    "style_preference": "fairy_tale"
  }
}
```

#### 📊 输出结果

生成的图像保存在 `data/output/images/` 目录：

```
images/
├── image_001.png     # 第1章第1场景
├── image_002.png     # 第1章第2场景
├── image_003.png     # 第2章第1场景
├── ...
└── generation_log.json  # 生成日志
```

**generation_log.json 示例：**
```json
{
  "total_images": 15,
  "successful": 14,
  "failed": 1,
  "generation_time": "00:12:34",
  "images": [
    {
      "id": "image_001",
      "chapter": 1,
      "scene": 1,
      "prompt": "A little girl in red hood...",
      "lora_used": "little_girl_lora:0.8",
      "generation_time": 45.2,
      "status": "success"
    }
  ]
}
```

### 🎙️ 语音合成模块 (Voice Synthesizer)

语音合成模块使用Azure TTS服务将文本转换为自然流畅的语音。

#### 🎯 主要功能

- **多语音角色**：支持多种中文语音角色
- **情感控制**：可配置语音风格和情感
- **批量处理**：按章节批量生成语音
- **格式优化**：输出高质量WAV格式音频

#### 🚀 使用方法

```bash
# 命令行执行
uv run main.py --module voice_synthesizer

# 或使用简写
uv run main.py -m voice_synthesizer
```

#### ⚙️ 配置参数

```python
# Azure TTS 配置
AZURE_SPEECH_KEY = "your_azure_speech_key"
AZURE_SPEECH_REGION = "eastus"

# 语音设置
VOICE_NAME = "zh-CN-XiaoxiaoNeural"       # 默认语音角色
SPEECH_RATE = "0%"                        # 语速调节 (-50% 到 +200%)
SPEECH_PITCH = "+0Hz"                     # 音调调节
SPEECH_VOLUME = "+0%"                     # 音量调节

# 输出格式
AUDIO_FORMAT = "riff-24khz-16bit-mono-pcm"  # 音频格式
AUDIO_SAMPLE_RATE = 24000                   # 采样率

# 处理设置
MAX_TEXT_LENGTH = 3000                      # 单次合成最大字符数
SSML_ENABLED = True                         # 启用SSML标记
```

#### 🎵 语音角色选择

**推荐的中文语音角色：**

| 角色名称 | 性别 | 年龄 | 风格特点 | 适用场景 |
|----------|------|------|----------|----------|
| `zh-CN-XiaoxiaoNeural` | 女 | 成人 | 温柔、亲切 | 故事叙述、儿童内容 |
| `zh-CN-YunxiNeural` | 男 | 成人 | 沉稳、专业 | 正式叙述、教育内容 |
| `zh-CN-XiaoyiNeural` | 女 | 青年 | 活泼、清新 | 青春故事、轻松内容 |
| `zh-CN-YunjianNeural` | 男 | 青年 | 阳光、友善 | 冒险故事、积极内容 |
| `zh-CN-XiaochenNeural` | 女 | 儿童 | 天真、可爱 | 儿童角色、童话故事 |

#### 🎭 SSML高级控制

使用SSML（Speech Synthesis Markup Language）可以精确控制语音效果：

```xml
<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="zh-CN">
  <voice name="zh-CN-XiaoxiaoNeural">
    <prosody rate="slow" pitch="+2st">
      "你好，世界！"
    </prosody>
    <break time="1s"/>
    <prosody rate="fast" volume="loud">
      小红帽兴奋地说道。
    </prosody>
  </voice>
</speak>
```

**SSML标签说明：**
- `<prosody>`: 控制语速、音调、音量
- `<break>`: 插入停顿
- `<emphasis>`: 强调特定词语
- `<say-as>`: 指定数字、日期的读法

#### 📊 输出结果

生成的音频文件保存在 `data/output/audio/` 目录：

```
audio/
├── chapter_1.wav     # 第1章音频
├── chapter_2.wav     # 第2章音频
├── chapter_3.wav     # 第3章音频
└── synthesis_log.json  # 合成日志
```

### 🎬 视频合成模块 (Video Composer)

视频合成模块将图像、音频和字幕合成为最终的视频文件。

#### 🎯 主要功能

- **多媒体合成**：合成图像序列、背景音频和字幕
- **章节视频**：为每个章节生成独立视频
- **完整视频**：合并所有章节为完整视频
- **字幕生成**：自动生成时间轴同步的字幕

#### 🚀 使用方法

```bash
# 命令行执行
uv run main.py --module video_composer

# 或使用简写
uv run main.py -m video_composer
```

#### ⚙️ 配置参数

```python
# 视频输出设置
VIDEO_WIDTH = 1920                    # 视频宽度
VIDEO_HEIGHT = 1080                   # 视频高度
VIDEO_FPS = 30                        # 帧率
VIDEO_CODEC = "libx264"               # 视频编码器
AUDIO_CODEC = "aac"                   # 音频编码器
VIDEO_BITRATE = "5000k"               # 视频比特率

# 图像显示设置
IMAGE_DURATION = 5.0                  # 每张图片显示时长（秒）
TRANSITION_DURATION = 0.5             # 转场时长
TRANSITION_TYPE = "fade"              # 转场类型

# 字幕设置
SUBTITLE_FONT = "Arial Unicode MS"    # 字幕字体
SUBTITLE_SIZE = 24                    # 字幕大小
SUBTITLE_COLOR = "white"              # 字幕颜色
SUBTITLE_OUTLINE_COLOR = "black"      # 字幕描边颜色
SUBTITLE_POSITION = "bottom"          # 字幕位置

# 背景音乐
BACKGROUND_MUSIC_ENABLED = False      # 启用背景音乐
BACKGROUND_MUSIC_VOLUME = 0.3         # 背景音乐音量
```

#### 🎨 视觉效果配置

**转场效果选项：**
```python
TRANSITION_EFFECTS = {
    "fade": "淡入淡出",
    "slide_left": "左滑",
    "slide_right": "右滑",
    "zoom_in": "放大",
    "zoom_out": "缩小",
    "dissolve": "溶解"
}
```

**字幕样式配置：**
```python
SUBTITLE_STYLES = {
    "default": {
        "font_family": "Arial Unicode MS",
        "font_size": 24,
        "color": "white",
        "outline_color": "black",
        "outline_width": 2,
        "position": "bottom",
        "margin": 50
    },
    "title": {
        "font_size": 36,
        "color": "gold",
        "position": "center"
    }
}
```

#### 📊 输出结果

生成的视频文件保存在 `data/output/videos/` 目录：

```
videos/
├── chapter_1.mp4         # 第1章视频
├── chapter_2.mp4         # 第2章视频
├── chapter_3.mp4         # 第3章视频
├── final_video.mp4       # 完整合并视频
├── subtitles/            # 字幕文件
│   ├── chapter_1.srt
│   ├── chapter_2.srt
│   └── chapter_3.srt
└── composition_log.json  # 合成日志
```

---

## 🚀 高级功能和技巧

本章节介绍Story Flow的高级功能、参数调优技巧和常见问题的解决方案，帮助用户充分发挥系统的潜力。

### 📚 多章节处理策略

#### 🎯 大型项目管理

对于包含多个章节的大型故事项目，Story Flow提供了高效的批量处理策略：

**章节分组处理：**
```python
# 在 src/config.py 中配置
BATCH_SIZE = 5                    # 每批处理的章节数
PARALLEL_CHAPTERS = 3             # 并行处理的章节数
CHAPTER_PROCESSING_DELAY = 2      # 章节间处理延迟（秒）

# 内存管理
MAX_MEMORY_USAGE = "4GB"          # 最大内存使用量
CLEAR_CACHE_INTERVAL = 10         # 缓存清理间隔（章节数）
```

**智能资源分配：**
```python
# 根据章节长度动态调整资源
RESOURCE_ALLOCATION = {
    "short_chapter": {          # <500字
        "max_scenes": 3,
        "image_quality": "standard",
        "voice_speed": "normal"
    },
    "medium_chapter": {         # 500-1500字
        "max_scenes": 6,
        "image_quality": "high",
        "voice_speed": "normal"
    },
    "long_chapter": {           # >1500字
        "max_scenes": 10,
        "image_quality": "ultra",
        "voice_speed": "slow"
    }
}
```

#### 📊 进度监控和恢复

**断点续传功能：**
```bash
# 启用断点续传
uv run main.py --auto --resume

# 从特定章节开始
uv run main.py --auto --start-from-chapter 3

# 跳过已完成的步骤
uv run main.py --auto --skip-completed
```

**进度文件示例：**
```json
{
  "project_id": "story_20241201_001",
  "total_chapters": 8,
  "completed_steps": {
    "text_analysis": true,
    "storyboard_generation": true,
    "image_generation": {
      "chapter_1": "completed",
      "chapter_2": "in_progress",
      "chapter_3": "pending"
    },
    "voice_synthesis": false,
    "video_composition": false
  },
  "last_updated": "2024-12-01T15:30:00Z"
}
```

### ⚙️ 参数调优指南

#### 🎨 图像生成优化

**质量与速度平衡：**
```python
# 高质量模式（适合最终输出）
HIGH_QUALITY_CONFIG = {
    "sampling_steps": 30,
    "cfg_scale": 8.0,
    "sampler_name": "DPM++ 2M Karras",
    "enable_upscaling": True,
    "upscale_factor": 2,
    "denoising_strength": 0.7
}

# 快速预览模式（适合测试）
FAST_PREVIEW_CONFIG = {
    "sampling_steps": 15,
    "cfg_scale": 6.0,
    "sampler_name": "Euler a",
    "enable_upscaling": False,
    "width": 768,
    "height": 512
}

# 平衡模式（推荐日常使用）
BALANCED_CONFIG = {
    "sampling_steps": 20,
    "cfg_scale": 7.0,
    "sampler_name": "DPM++ 2M Karras",
    "enable_upscaling": True,
    "upscale_factor": 1.5
}
```

**LoRA权重调优：**
```json
{
  "角色一致性调优": {
    "主角": {
      "lora_weight": 0.8,
      "trigger_words": ["specific_character"],
      "negative_prompts": ["different_character", "multiple_people"]
    },
    "配角": {
      "lora_weight": 0.6,
      "trigger_words": ["supporting_character"],
      "blend_mode": "soft"
    }
  },
  "风格一致性": {
    "art_style_lora": 0.7,
    "color_palette_lora": 0.5,
    "lighting_style_lora": 0.4
  }
}
```

#### 🎙️ 语音合成优化

**情感表达配置：**
```python
# 根据内容类型调整语音参数
VOICE_EMOTION_CONFIG = {
    "narrative": {              # 叙述部分
        "rate": "0%",
        "pitch": "+0Hz",
        "volume": "+0%",
        "style": "calm"
    },
    "dialogue": {              # 对话部分
        "rate": "+10%",
        "pitch": "+2Hz",
        "volume": "+5%",
        "style": "cheerful"
    },
    "action": {                # 动作场景
        "rate": "+20%",
        "pitch": "+5Hz",
        "volume": "+10%",
        "style": "excited"
    },
    "suspense": {              # 悬疑场景
        "rate": "-10%",
        "pitch": "-2Hz",
        "volume": "-5%",
        "style": "whisper"
    }
}
```

**多角色语音配置：**
```python
CHARACTER_VOICES = {
    "narrator": "zh-CN-XiaoxiaoNeural",     # 旁白
    "protagonist": "zh-CN-XiaoyiNeural",   # 主角
    "antagonist": "zh-CN-YunxiNeural",     # 反派
    "child": "zh-CN-XiaochenNeural",       # 儿童角色
    "elder": "zh-CN-YunyangNeural"         # 长者角色
}
```

#### 🎬 视频合成优化

**性能优化配置：**
```python
# GPU加速设置
VIDEO_ACCELERATION = {
    "enable_gpu": True,
    "gpu_codec": "h264_nvenc",      # NVIDIA GPU
    "gpu_preset": "fast",          # 编码预设
    "gpu_memory_limit": "6GB"      # GPU内存限制
}

# 多线程渲染
RENDER_THREADS = {
    "video_threads": 4,             # 视频处理线程
    "audio_threads": 2,             # 音频处理线程
    "subtitle_threads": 1           # 字幕处理线程
}

# 质量预设
QUALITY_PRESETS = {
    "ultra": {
        "bitrate": "8000k",
        "crf": 18,
        "preset": "slow"
    },
    "high": {
        "bitrate": "5000k",
        "crf": 23,
        "preset": "medium"
    },
    "standard": {
        "bitrate": "3000k",
        "crf": 28,
        "preset": "fast"
    }
}
```

### 🔧 故障排除指南

#### ❌ 常见错误及解决方案

**1. API连接问题**

```bash
# 错误信息
ConnectionError: Failed to connect to OpenAI API

# 解决方案
# 1. 检查网络连接
ping api.openai.com

# 2. 验证API密钥
export OPENAI_API_KEY="your_actual_key"
echo $OPENAI_API_KEY

# 3. 检查API配额
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
     https://api.openai.com/v1/usage

# 4. 使用代理（如需要）
export HTTP_PROXY="http://proxy.company.com:8080"
export HTTPS_PROXY="http://proxy.company.com:8080"
```

**2. Stable Diffusion连接失败**

```bash
# 错误信息
ConnectionError: Failed to connect to Stable Diffusion WebUI

# 解决方案
# 1. 检查WebUI是否运行
curl http://127.0.0.1:7860/sdapi/v1/options

# 2. 启动WebUI（如果未运行）
cd /path/to/stable-diffusion-webui
./webui.sh --api --listen

# 3. 检查端口配置
netstat -an | grep 7860

# 4. 修改配置文件中的地址
# 在 .env 文件中：
SD_API_BASE_URL="http://127.0.0.1:7860"
```

**3. 内存不足问题**

```bash
# 错误信息
MemoryError: Unable to allocate memory for image generation

# 解决方案
# 1. 减少并发数
MAX_CONCURRENT_IMAGES = 1

# 2. 降低图像分辨率
IMAGE_WIDTH = 768
IMAGE_HEIGHT = 512

# 3. 启用内存优化
ENABLE_MEMORY_OPTIMIZATION = True
CLEAR_CACHE_AFTER_GENERATION = True

# 4. 监控内存使用
htop  # 或 Activity Monitor (macOS)
```

**4. 文件权限问题**

```bash
# 错误信息
PermissionError: [Errno 13] Permission denied

# 解决方案
# 1. 检查文件权限
ls -la data/

# 2. 修改权限
chmod -R 755 data/
chown -R $USER:$USER data/

# 3. 检查磁盘空间
df -h

# 4. 创建必要目录
mkdir -p data/output/{chapters,images,audio,videos}
```

#### 🔍 调试技巧

**启用详细日志：**
```bash
# 在 .env 文件中设置
LOG_LEVEL=DEBUG
ENABLE_FILE_LOGGING=true
LOG_FILE_PATH="logs/story_flow.log"

# 运行时查看日志
tail -f logs/story_flow.log
```

**性能分析：**
```python
# 在 src/config.py 中启用
ENABLE_PROFILING = True
PROFILE_OUTPUT_DIR = "logs/profiles"

# 分析结果
# 会生成 .prof 文件，可用 snakeviz 查看
pip install snakeviz
snakeviz logs/profiles/generation_profile.prof
```

**测试模式：**
```bash
# 快速测试模式（使用小数据集）
uv run main.py --test-mode

# 单步调试模式
uv run main.py --debug --step-by-step

# 跳过耗时步骤
uv run main.py --skip-image-generation --skip-video-composition
```

#### 📊 性能监控

**系统资源监控：**
```python
# 在处理过程中监控资源使用
import psutil

def monitor_resources():
    cpu_percent = psutil.cpu_percent(interval=1)
    memory = psutil.virtual_memory()
    disk = psutil.disk_usage('/')
    
    print(f"CPU使用率: {cpu_percent}%")
    print(f"内存使用率: {memory.percent}%")
    print(f"磁盘使用率: {disk.percent}%")
```

**处理时间分析：**
```python
# 各模块处理时间统计
PROCESSING_TIMES = {
    "text_analysis": "00:00:15",
    "storyboard_generation": "00:02:30",
    "image_generation": "00:15:45",
    "voice_synthesis": "00:03:20",
    "video_composition": "00:08:10",
    "total_time": "00:30:00"
}
```

### 💡 最佳实践建议

#### 🎯 项目规划

1. **内容准备**：
   - 确保故事结构清晰，章节划分合理
   - 预先规划主要角色和场景
   - 准备角色LoRA模型和触发词

2. **资源配置**：
   - 根据项目规模调整并发数和内存限制
   - 预估处理时间和存储空间需求
   - 准备备用API密钥和服务

3. **质量控制**：
   - 先用快速模式测试整个流程
   - 逐步提高质量参数
   - 定期备份中间结果

#### 🚀 效率优化

1. **批量处理**：
   - 合理设置批处理大小
   - 利用并发处理能力
   - 避免频繁的API调用

2. **缓存策略**：
   - 启用中间结果缓存
   - 定期清理临时文件
   - 复用相似场景的生成结果

3. **错误恢复**：
   - 启用断点续传功能
   - 设置合理的重试机制
   - 监控处理进度和错误日志

---

## 📁 输出文件管理与项目维护

本章节介绍如何有效管理Story Flow生成的各类文件，以及项目的日常维护和优化策略。

### 📂 文件结构管理

#### 🗂️ 标准输出目录结构

Story Flow会在 `data/output/` 目录下生成以下文件结构：

```
data/output/
├── chapters/                    # 章节文件
│   ├── chapter_1.md
│   ├── chapter_2.md
│   ├── chapter_3.md
│   └── metadata.json
├── storyboard/                  # 故事板文件
│   ├── storyboard.csv
│   └── storyboard_analysis.json
├── images/                      # 生成的图像
│   ├── image_001.png
│   ├── image_002.png
│   ├── image_003.png
│   ├── thumbnails/              # 缩略图
│   │   ├── thumb_001.jpg
│   │   └── thumb_002.jpg
│   └── generation_log.json
├── audio/                       # 语音文件
│   ├── chapter_1.wav
│   ├── chapter_2.wav
│   ├── chapter_3.wav
│   └── synthesis_log.json
├── videos/                      # 视频文件
│   ├── chapters/                # 章节视频
│   │   ├── chapter_1.mp4
│   │   ├── chapter_2.mp4
│   │   └── chapter_3.mp4
│   ├── final_video.mp4          # 完整视频
│   ├── subtitles/               # 字幕文件
│   │   ├── chapter_1.srt
│   │   ├── chapter_2.srt
│   │   └── chapter_3.srt
│   └── composition_log.json
├── temp/                        # 临时文件
│   ├── processing/
│   └── cache/
└── backups/                     # 备份文件
    ├── 2024-12-01_backup/
    └── 2024-12-02_backup/
```

#### 📊 文件大小估算

**典型项目文件大小参考：**

| 文件类型 | 单个文件大小 | 10章节项目总大小 | 备注 |
|----------|-------------|-----------------|------|
| 章节文件(.md) | 2-10 KB | 50-100 KB | 纯文本，占用很小 |
| 故事板文件(.csv) | 5-20 KB | 50-200 KB | 结构化数据 |
| 图像文件(.png) | 1-5 MB | 50-250 MB | 取决于分辨率和质量 |
| 音频文件(.wav) | 5-15 MB | 50-150 MB | 取决于章节长度 |
| 视频文件(.mp4) | 20-100 MB | 200MB-1GB | 取决于质量和长度 |
| **项目总计** | - | **350MB-1.5GB** | 不含备份和临时文件 |

### 🧹 文件清理策略

#### 🗑️ 自动清理配置

在 `src/config.py` 中配置自动清理策略：

```python
# 文件清理配置
FILE_CLEANUP_CONFIG = {
    "enable_auto_cleanup": True,
    "cleanup_interval_days": 7,        # 清理间隔（天）
    "keep_backups_count": 5,           # 保留备份数量
    "temp_file_retention_hours": 24,   # 临时文件保留时间（小时）
    "log_file_retention_days": 30,     # 日志文件保留时间（天）
}

# 清理规则
CLEANUP_RULES = {
    "temp_files": {
        "path": "data/output/temp/",
        "pattern": "*.tmp",
        "max_age_hours": 24
    },
    "cache_files": {
        "path": "data/output/temp/cache/",
        "pattern": "*",
        "max_age_hours": 72
    },
    "old_logs": {
        "path": "logs/",
        "pattern": "*.log.*",
        "max_age_days": 30
    },
    "failed_generations": {
        "path": "data/output/images/",
        "pattern": "failed_*.png",
        "max_age_hours": 48
    }
}
```

#### 🔧 手动清理命令

```bash
# 清理临时文件
uv run main.py --cleanup temp

# 清理缓存文件
uv run main.py --cleanup cache

# 清理旧日志
uv run main.py --cleanup logs

# 全面清理（保留重要文件）
uv run main.py --cleanup all

# 深度清理（删除所有非必要文件）
uv run main.py --cleanup deep --confirm
```

#### 📋 清理脚本示例

创建自定义清理脚本 `scripts/cleanup.py`：

```python
#!/usr/bin/env python3
"""
文件清理脚本
用法: python scripts/cleanup.py [options]
"""

import os
import glob
import shutil
from datetime import datetime, timedelta
import argparse

def cleanup_old_files(directory, pattern, max_age_days):
    """清理指定目录下的旧文件"""
    cutoff_date = datetime.now() - timedelta(days=max_age_days)
    files_removed = 0
    
    for file_path in glob.glob(os.path.join(directory, pattern)):
        if os.path.isfile(file_path):
            file_mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
            if file_mtime < cutoff_date:
                os.remove(file_path)
                files_removed += 1
                print(f"已删除: {file_path}")
    
    return files_removed

def cleanup_empty_directories(root_dir):
    """清理空目录"""
    dirs_removed = 0
    for root, dirs, files in os.walk(root_dir, topdown=False):
        for dir_name in dirs:
            dir_path = os.path.join(root, dir_name)
            try:
                if not os.listdir(dir_path):  # 目录为空
                    os.rmdir(dir_path)
                    dirs_removed += 1
                    print(f"已删除空目录: {dir_path}")
            except OSError:
                pass  # 目录不为空或无权限
    
    return dirs_removed

def get_directory_size(directory):
    """获取目录大小"""
    total_size = 0
    for root, dirs, files in os.walk(directory):
        for file in files:
            file_path = os.path.join(root, file)
            if os.path.exists(file_path):
                total_size += os.path.getsize(file_path)
    return total_size

def format_size(size_bytes):
    """格式化文件大小"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.1f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.1f} TB"

def main():
    parser = argparse.ArgumentParser(description='Story Flow 文件清理工具')
    parser.add_argument('--dry-run', action='store_true', help='预览模式，不实际删除文件')
    parser.add_argument('--temp', action='store_true', help='清理临时文件')
    parser.add_argument('--cache', action='store_true', help='清理缓存文件')
    parser.add_argument('--logs', action='store_true', help='清理旧日志')
    parser.add_argument('--all', action='store_true', help='执行全面清理')
    
    args = parser.parse_args()
    
    print("=== Story Flow 文件清理工具 ===")
    
    # 显示清理前的磁盘使用情况
    output_dir = "data/output"
    if os.path.exists(output_dir):
        before_size = get_directory_size(output_dir)
        print(f"清理前输出目录大小: {format_size(before_size)}")
    
    total_files_removed = 0
    total_dirs_removed = 0
    
    if args.temp or args.all:
        print("\n清理临时文件...")
        files_removed = cleanup_old_files("data/output/temp", "*", 1)
        total_files_removed += files_removed
        print(f"清理了 {files_removed} 个临时文件")
    
    if args.cache or args.all:
        print("\n清理缓存文件...")
        files_removed = cleanup_old_files("data/output/temp/cache", "*", 3)
        total_files_removed += files_removed
        print(f"清理了 {files_removed} 个缓存文件")
    
    if args.logs or args.all:
        print("\n清理旧日志文件...")
        files_removed = cleanup_old_files("logs", "*.log.*", 30)
        total_files_removed += files_removed
        print(f"清理了 {files_removed} 个日志文件")
    
    if args.all:
        print("\n清理空目录...")
        dirs_removed = cleanup_empty_directories("data/output")
        total_dirs_removed += dirs_removed
        print(f"清理了 {dirs_removed} 个空目录")
    
    # 显示清理后的磁盘使用情况
    if os.path.exists(output_dir):
        after_size = get_directory_size(output_dir)
        saved_size = before_size - after_size
        print(f"\n清理后输出目录大小: {format_size(after_size)}")
        print(f"节省磁盘空间: {format_size(saved_size)}")
    
    print(f"\n清理完成！")
    print(f"删除文件: {total_files_removed} 个")
    print(f"删除目录: {total_dirs_removed} 个")

if __name__ == "__main__":
    main()
```

### 💾 备份策略

#### 🔄 自动备份配置

```python
# 备份配置
BACKUP_CONFIG = {
    "enable_auto_backup": True,
    "backup_interval_hours": 6,        # 备份间隔（小时）
    "backup_retention_days": 30,       # 备份保留时间（天）
    "backup_compression": True,        # 启用压缩
    "backup_location": "data/backups", # 备份位置
    "remote_backup": {                 # 远程备份（可选）
        "enabled": False,
        "provider": "s3",              # s3, gdrive, dropbox
        "bucket": "story-flow-backups",
        "access_key": "AKIA****************",
        "secret_key": "****************************************"
    }
}

# 备份内容配置
BACKUP_INCLUDES = [
    "input.md",                        # 输入文件
    "character_mapping.json",         # 角色映射
    "data/output/chapters/",          # 章节文件
    "data/output/storyboard/",        # 故事板
    "data/output/images/",            # 图像（可选）
    "data/output/audio/",             # 音频（可选）
    "data/output/videos/final_video.mp4", # 最终视频
    ".env",                           # 环境配置（敏感信息需加密）
]

BACKUP_EXCLUDES = [
    "data/output/temp/",              # 临时文件
    "data/output/cache/",             # 缓存文件
    "logs/",                          # 日志文件
    "*.tmp",                          # 临时文件
    "*.log",                          # 日志文件
]
```

#### 📦 备份脚本

创建备份脚本 `scripts/backup.py`：

```python
#!/usr/bin/env python3
"""
项目备份脚本
用法: python scripts/backup.py [options]
"""

import os
import shutil
import tarfile
import gzip
from datetime import datetime
import argparse
import json

def create_backup(backup_name=None, compress=True):
    """创建项目备份"""
    if not backup_name:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"story_flow_backup_{timestamp}"
    
    backup_dir = f"data/backups/{backup_name}"
    os.makedirs(backup_dir, exist_ok=True)
    
    # 备份文件列表
    files_to_backup = [
        "input.md",
        "character_mapping.json",
        "data/output/chapters/",
        "data/output/storyboard/",
        "data/output/images/",
        "data/output/audio/",
        "data/output/videos/final_video.mp4"
    ]
    
    backup_info = {
        "backup_name": backup_name,
        "created_at": datetime.now().isoformat(),
        "files": [],
        "total_size": 0
    }
    
    print(f"创建备份: {backup_name}")
    
    for item in files_to_backup:
        if os.path.exists(item):
            dest_path = os.path.join(backup_dir, item)
            os.makedirs(os.path.dirname(dest_path), exist_ok=True)
            
            if os.path.isfile(item):
                shutil.copy2(item, dest_path)
                size = os.path.getsize(item)
            else:
                shutil.copytree(item, dest_path, dirs_exist_ok=True)
                size = get_directory_size(item)
            
            backup_info["files"].append({
                "path": item,
                "size": size,
                "type": "file" if os.path.isfile(item) else "directory"
            })
            backup_info["total_size"] += size
            
            print(f"  已备份: {item} ({format_size(size)})")
    
    # 保存备份信息
    with open(os.path.join(backup_dir, "backup_info.json"), "w", encoding="utf-8") as f:
        json.dump(backup_info, f, indent=2, ensure_ascii=False)
    
    # 压缩备份（如果启用）
    if compress:
        archive_path = f"{backup_dir}.tar.gz"
        with tarfile.open(archive_path, "w:gz") as tar:
            tar.add(backup_dir, arcname=backup_name)
        
        # 删除未压缩的备份目录
        shutil.rmtree(backup_dir)
        
        archive_size = os.path.getsize(archive_path)
        print(f"\n备份已压缩: {archive_path}")
        print(f"压缩后大小: {format_size(archive_size)}")
        print(f"压缩率: {(1 - archive_size / backup_info['total_size']) * 100:.1f}%")
    
    print(f"\n备份完成！总大小: {format_size(backup_info['total_size'])}")
    return backup_name

def restore_backup(backup_name, target_dir="."):
    """恢复备份"""
    backup_path = f"data/backups/{backup_name}"
    archive_path = f"{backup_path}.tar.gz"
    
    if os.path.exists(archive_path):
        print(f"恢复压缩备份: {archive_path}")
        with tarfile.open(archive_path, "r:gz") as tar:
            tar.extractall(path="data/backups")
        backup_path = f"data/backups/{backup_name}"
    
    if not os.path.exists(backup_path):
        print(f"错误: 备份不存在 {backup_path}")
        return False
    
    # 读取备份信息
    info_file = os.path.join(backup_path, "backup_info.json")
    if os.path.exists(info_file):
        with open(info_file, "r", encoding="utf-8") as f:
            backup_info = json.load(f)
        print(f"恢复备份: {backup_info['backup_name']}")
        print(f"创建时间: {backup_info['created_at']}")
    
    # 恢复文件
    for root, dirs, files in os.walk(backup_path):
        for file in files:
            if file == "backup_info.json":
                continue
            
            src_path = os.path.join(root, file)
            rel_path = os.path.relpath(src_path, backup_path)
            dest_path = os.path.join(target_dir, rel_path)
            
            os.makedirs(os.path.dirname(dest_path), exist_ok=True)
            shutil.copy2(src_path, dest_path)
            print(f"  已恢复: {rel_path}")
    
    print("\n备份恢复完成！")
    return True

def list_backups():
    """列出所有备份"""
    backup_dir = "data/backups"
    if not os.path.exists(backup_dir):
        print("没有找到备份目录")
        return
    
    backups = []
    
    # 查找压缩备份
    for file in os.listdir(backup_dir):
        if file.endswith(".tar.gz"):
            backup_name = file[:-7]  # 移除 .tar.gz
            file_path = os.path.join(backup_dir, file)
            size = os.path.getsize(file_path)
            mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
            
            backups.append({
                "name": backup_name,
                "type": "compressed",
                "size": size,
                "created": mtime
            })
    
    # 查找未压缩备份
    for item in os.listdir(backup_dir):
        item_path = os.path.join(backup_dir, item)
        if os.path.isdir(item_path) and not item.endswith(".tar.gz"):
            size = get_directory_size(item_path)
            mtime = datetime.fromtimestamp(os.path.getmtime(item_path))
            
            backups.append({
                "name": item,
                "type": "directory",
                "size": size,
                "created": mtime
            })
    
    if not backups:
        print("没有找到备份文件")
        return
    
    # 按创建时间排序
    backups.sort(key=lambda x: x["created"], reverse=True)
    
    print("\n可用备份列表:")
    print("-" * 80)
    print(f"{'备份名称':<30} {'类型':<10} {'大小':<15} {'创建时间':<20}")
    print("-" * 80)
    
    for backup in backups:
        print(f"{backup['name']:<30} {backup['type']:<10} {format_size(backup['size']):<15} {backup['created'].strftime('%Y-%m-%d %H:%M:%S'):<20}")

def get_directory_size(directory):
    """获取目录大小"""
    total_size = 0
    for root, dirs, files in os.walk(directory):
        for file in files:
            file_path = os.path.join(root, file)
            if os.path.exists(file_path):
                total_size += os.path.getsize(file_path)
    return total_size

def format_size(size_bytes):
    """格式化文件大小"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.1f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.1f} TB"

def main():
    parser = argparse.ArgumentParser(description='Story Flow 备份工具')
    parser.add_argument('action', choices=['create', 'restore', 'list'], help='操作类型')
    parser.add_argument('--name', help='备份名称')
    parser.add_argument('--no-compress', action='store_true', help='不压缩备份')
    parser.add_argument('--target', default='.', help='恢复目标目录')
    
    args = parser.parse_args()
    
    if args.action == 'create':
        create_backup(args.name, not args.no_compress)
    elif args.action == 'restore':
        if not args.name:
            print("错误: 恢复备份需要指定备份名称")
            return
        restore_backup(args.name, args.target)
    elif args.action == 'list':
        list_backups()

if __name__ == "__main__":
    main()
```

### 🔧 项目维护

#### 📅 定期维护任务

**每日维护：**
```bash
# 检查系统状态
uv run main.py --health-check

# 清理临时文件
python scripts/cleanup.py --temp

# 检查磁盘空间
df -h
```

**每周维护：**
```bash
# 创建备份
python scripts/backup.py create

# 全面清理
python scripts/cleanup.py --all

# 更新依赖
uv sync
```

**每月维护：**
```bash
# 清理旧备份
find data/backups -name "*.tar.gz" -mtime +30 -delete

# 检查配置文件
uv run main.py --validate-config

# 性能分析
uv run main.py --performance-report
```

#### 🔍 健康检查脚本

创建健康检查脚本 `scripts/health_check.py`：

```python
#!/usr/bin/env python3
"""
系统健康检查脚本
"""

import os
import sys
import json
import requests
from datetime import datetime

def check_dependencies():
    """检查依赖项"""
    print("检查依赖项...")
    
    required_packages = [
        'openai', 'requests', 'pillow', 'opencv-python',
        'azure-cognitiveservices-speech', 'moviepy'
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package.replace('-', '_'))
            print(f"  ✓ {package}")
        except ImportError:
            print(f"  ✗ {package} (缺失)")
            missing_packages.append(package)
    
    return len(missing_packages) == 0

def check_api_connections():
    """检查API连接"""
    print("\n检查API连接...")
    
    # 检查OpenAI API
    openai_key = os.getenv('OPENAI_API_KEY')
    if openai_key:
        try:
            headers = {'Authorization': f'Bearer {openai_key}'}
            response = requests.get('https://api.openai.com/v1/models', headers=headers, timeout=10)
            if response.status_code == 200:
                print("  ✓ OpenAI API 连接正常")
            else:
                print(f"  ✗ OpenAI API 连接失败 (状态码: {response.status_code})")
        except Exception as e:
            print(f"  ✗ OpenAI API 连接失败: {e}")
    else:
        print("  ⚠ OpenAI API 密钥未配置")
    
    # 检查Stable Diffusion API
    sd_url = os.getenv('SD_API_BASE_URL', 'http://127.0.0.1:7860')
    try:
        response = requests.get(f'{sd_url}/sdapi/v1/options', timeout=5)
        if response.status_code == 200:
            print("  ✓ Stable Diffusion API 连接正常")
        else:
            print(f"  ✗ Stable Diffusion API 连接失败 (状态码: {response.status_code})")
    except Exception as e:
        print(f"  ✗ Stable Diffusion API 连接失败: {e}")
    
    # 检查Azure Speech API
    azure_key = os.getenv('AZURE_SPEECH_KEY')
    if azure_key:
        print("  ✓ Azure Speech API 密钥已配置")
    else:
        print("  ⚠ Azure Speech API 密钥未配置")

def check_disk_space():
    """检查磁盘空间"""
    print("\n检查磁盘空间...")
    
    import shutil
    total, used, free = shutil.disk_usage(".")
    
    print(f"  总空间: {format_size(total)}")
    print(f"  已使用: {format_size(used)} ({used/total*100:.1f}%)")
    print(f"  可用空间: {format_size(free)} ({free/total*100:.1f}%)")
    
    if free < 1024**3:  # 小于1GB
        print("  ⚠ 磁盘空间不足，建议清理文件")
        return False
    else:
        print("  ✓ 磁盘空间充足")
        return True

def check_output_directory():
    """检查输出目录结构"""
    print("\n检查输出目录结构...")
    
    required_dirs = [
        'data/output/chapters',
        'data/output/images',
        'data/output/audio',
        'data/output/videos',
        'data/output/temp',
        'data/backups',
        'logs'
    ]
    
    all_exist = True
    for dir_path in required_dirs:
        if os.path.exists(dir_path):
            print(f"  ✓ {dir_path}")
        else:
            print(f"  ✗ {dir_path} (不存在)")
            all_exist = False
            # 自动创建目录
            os.makedirs(dir_path, exist_ok=True)
            print(f"    已创建目录: {dir_path}")
    
    return all_exist

def format_size(size_bytes):
    """格式化文件大小"""
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.1f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.1f} PB"

def generate_health_report():
    """生成健康检查报告"""
    print("\n=== Story Flow 系统健康检查报告 ===")
    print(f"检查时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 50)
    
    checks = {
        "依赖项检查": check_dependencies(),
        "磁盘空间检查": check_disk_space(),
        "输出目录检查": check_output_directory()
    }
    
    check_api_connections()
    
    print("\n=== 检查结果汇总 ===")
    all_passed = True
    for check_name, result in checks.items():
        status = "✓ 通过" if result else "✗ 失败"
        print(f"{check_name}: {status}")
        if not result:
            all_passed = False
    
    if all_passed:
        print("\n🎉 系统状态良好！")
        return 0
    else:
        print("\n⚠️  发现问题，请检查上述失败项目")
        return 1

if __name__ == "__main__":
    sys.exit(generate_health_report())
```

#### 🚀 性能优化建议

**存储优化：**
1. 定期清理临时文件和缓存
2. 压缩旧的备份文件
3. 使用SSD存储提高I/O性能
4. 考虑使用外部存储服务（如云存储）

**内存优化：**
1. 调整并发处理数量
2. 启用内存优化选项
3. 定期重启长时间运行的进程
4. 监控内存使用情况

**网络优化：**
1. 使用CDN加速API访问
2. 配置合理的超时和重试机制
3. 启用请求缓存
4. 考虑使用代理服务器

---

## ❓ 常见问题解答 (FAQ)

### 🔧 安装和配置问题

**Q: 安装依赖时出现错误怎么办？**
A: 
1. 确保使用 `uv` 而不是 `pip`
2. 检查Python版本是否为3.8+
3. 尝试清理缓存：`uv cache clean`
4. 如果是网络问题，可以配置镜像源

**Q: API密钥配置后仍然报错？**
A:
1. 检查 `.env` 文件是否在项目根目录
2. 确认密钥格式正确，没有多余的空格
3. 验证API密钥是否有效且有足够的配额
4. 重启程序以重新加载环境变量

**Q: Stable Diffusion连接失败？**
A:
1. 确认Stable Diffusion WebUI已启动
2. 检查端口号是否正确（默认7860）
3. 确认防火墙没有阻止连接
4. 尝试在浏览器中访问 `http://127.0.0.1:7860`

### 🎨 生成质量问题

**Q: 生成的故事质量不理想？**
A:
1. 优化故事主题描述，提供更多细节
2. 尝试不同的AI模型（GPT-4 vs GPT-3.5）
3. 调整生成参数（温度、最大长度等）
4. 多次生成并选择最佳结果

**Q: 图像生成效果不好？**
A:
1. 优化提示词，使用更具体的描述
2. 调整图像生成参数（步数、CFG Scale）
3. 尝试不同的LoRA模型
4. 检查角色映射配置是否正确

**Q: 语音合成听起来不自然？**
A:
1. 调整语音参数（语速、音调）
2. 尝试不同的语音模型
3. 优化文本内容，避免过长的句子
4. 检查标点符号是否正确

### 🚀 性能问题

**Q: 处理速度很慢？**
A:
1. 检查网络连接速度
2. 调整并发处理数量
3. 使用更快的硬件（SSD、更多内存）
4. 启用缓存功能

**Q: 内存不足错误？**
A:
1. 减少并发处理数量
2. 降低图像分辨率
3. 清理临时文件
4. 增加系统内存或使用虚拟内存

**Q: 磁盘空间不足？**
A:
1. 运行清理脚本：`python scripts/cleanup.py --all`
2. 删除不需要的备份文件
3. 压缩或移动大文件到外部存储
4. 调整输出质量设置

### 📁 文件管理问题

**Q: 找不到生成的文件？**
A:
1. 检查 `data/output/` 目录
2. 查看日志文件了解处理状态
3. 确认处理过程是否完成
4. 检查文件权限设置

**Q: 如何恢复意外删除的文件？**
A:
1. 检查 `data/backups/` 目录
2. 使用备份恢复：`python scripts/backup.py restore --name backup_name`
3. 查看系统回收站
4. 使用文件恢复工具

---

## 📚 附录

### 📖 相关资源

**官方文档：**
- [OpenAI API 文档](https://platform.openai.com/docs)
- [Stable Diffusion WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
- [Azure Speech Services](https://docs.microsoft.com/azure/cognitive-services/speech-service/)

**社区资源：**
- [Story Flow GitHub 仓库](https://github.com/story-flow/story-flow)
- [用户交流群](https://discord.gg/story-flow)
- [问题反馈](https://github.com/story-flow/story-flow/issues)

**学习资源：**
- [AI绘画提示词指南](https://prompthero.com/)
- [视频制作教程](https://www.youtube.com/playlist?list=story-flow-tutorials)
- [最佳实践案例](https://github.com/story-flow/story-flow/wiki/best-practices)

### 🔄 版本更新日志

**v2.0.0 (2024-12-01)**
- 新增多章节批量处理功能
- 优化图像生成质量
- 改进错误处理和日志记录
- 添加自动备份功能

**v1.5.0 (2024-11-15)**
- 支持自定义角色LoRA模型
- 新增视频字幕功能
- 优化内存使用
- 修复已知bug

**v1.0.0 (2024-10-01)**
- 首个正式版本发布
- 完整的故事生成流水线
- 基础的图像、音频、视频生成功能

### 📞 技术支持

**获取帮助的方式：**

1. **查看文档**：首先查阅本教程和官方文档
2. **搜索问题**：在GitHub Issues中搜索类似问题
3. **社区求助**：在用户交流群中提问
4. **提交Issue**：在GitHub上提交详细的问题报告
5. **联系开发者**：通过邮件联系技术支持

**提交问题时请包含：**
- 操作系统和Python版本
- Story Flow版本号
- 详细的错误信息和日志
- 复现步骤
- 相关配置文件（去除敏感信息）

**联系方式：**
- 📧 邮箱：support@story-flow.com
- 💬 Discord：[Story Flow Community](https://discord.gg/story-flow)
- 🐛 GitHub Issues：[提交问题](https://github.com/story-flow/story-flow/issues)
- 📱 微信群：扫描二维码加入用户群

---

## 🎉 结语

恭喜您完成了Story Flow用户操作教程的学习！

通过本教程，您已经掌握了：
- ✅ Story Flow的基本概念和核心功能
- ✅ 完整的配置和安装流程
- ✅ AI故事生成的使用方法
- ✅ 完整流水线的操作技巧
- ✅ 各个模块的详细使用方法
- ✅ 高级功能和性能优化技巧
- ✅ 文件管理和项目维护策略

**接下来的建议：**

1. **实践练习**：从一个简单的故事开始，逐步尝试各种功能
2. **参数调优**：根据您的需求调整各种参数设置
3. **社区参与**：加入用户社区，分享经验和获取帮助
4. **持续学习**：关注项目更新，学习新功能和最佳实践

**创作愉快！** 🚀

Story Flow团队致力于为创作者提供最好的AI辅助创作工具。如果您在使用过程中有任何建议或反馈，欢迎随时联系我们。让我们一起创造更精彩的故事世界！

---

*本教程最后更新时间：2024年12月01日*  
*教程版本：v2.0*  
*适用于Story Flow v2.0.0及以上版本*