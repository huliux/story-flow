#!/usr/bin/env python3
"""
æµ‹è¯•å¤§è¯­è¨€æ¨¡å‹æœåŠ¡
æ”¯æŒOpenAIå’ŒDeepSeekçš„åŠŸèƒ½æµ‹è¯•
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.config import config
from src.llm_client import llm_client

def test_provider_info():
    """æµ‹è¯•æœåŠ¡å•†ä¿¡æ¯"""
    print("ğŸ” æµ‹è¯•æœåŠ¡å•†ä¿¡æ¯...")
    info = llm_client.get_provider_info()
    print(f"âœ… æœåŠ¡å•†: {info['provider']}")
    print(f"âœ… æ¨¡å‹: {info['model']}")
    print(f"âœ… APIåœ°å€: {info['api_base']}")
    print(f"âœ… APIå¯†é’¥: {'å·²é…ç½®' if info['has_api_key'] else 'æœªé…ç½®'}")
    return info['has_api_key']

def test_translation():
    """æµ‹è¯•æ–‡æœ¬ç¿»è¯‘åŠŸèƒ½"""
    print("\nğŸ”¤ æµ‹è¯•æ–‡æœ¬ç¿»è¯‘...")
    test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯AIç¿»è¯‘åŠŸèƒ½ã€‚"
    
    try:
        result = llm_client.translate_to_english(test_text)
        print(f"åŸæ–‡: {test_text}")
        print(f"è¯‘æ–‡: {result}")
        return True
    except Exception as e:
        print(f"âŒ ç¿»è¯‘å¤±è´¥: {e}")
        return False

def test_storyboard():
    """æµ‹è¯•åˆ†é•œè„šæœ¬ç”Ÿæˆ"""
    print("\nğŸ¬ æµ‹è¯•åˆ†é•œè„šæœ¬ç”Ÿæˆ...")
    test_text = "ä¸€ä¸ªå¹´è½»çš„å¥³å­©åœ¨èŠ±å›­é‡Œæ•£æ­¥ï¼Œå¥¹ç©¿ç€ç™½è‰²çš„è¿è¡£è£™ã€‚"
    
    try:
        messages = [
            {"role": "system", "content": "You are a professional storyboard assistant."},
            {"role": "user", "content": f"Based on the text \"{test_text}\", create a storyboard. Create a detailed description for image generation."}
        ]
        result = llm_client.chat_completion(messages)
        print(f"åŸæ–‡: {test_text}")
        print(f"åˆ†é•œ: {result}")
        return True
    except Exception as e:
        print(f"âŒ åˆ†é•œç”Ÿæˆå¤±è´¥: {e}")
        return False

def test_api_limits():
    """æµ‹è¯•APIé™åˆ¶å’Œé‡è¯•æœºåˆ¶"""
    print("\nâ±ï¸ æµ‹è¯•APIé…ç½®...")
    print(f"æœ€å¤§ä»¤ç‰Œæ•°: {config.llm_max_tokens}")
    print(f"æ¸©åº¦å‚æ•°: {config.llm_temperature}")
    print(f"å†·å´æ—¶é—´: {config.llm_cooldown_seconds}ç§’")
    print(f"æœ€å¤§è¯·æ±‚æ•°: {config.llm_max_requests}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¤§è¯­è¨€æ¨¡å‹æœåŠ¡æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•é…ç½®
    print(f"å½“å‰LLMæœåŠ¡å•†: {config.llm_provider}")
    
    # æµ‹è¯•æœåŠ¡å•†ä¿¡æ¯
    has_key = test_provider_info()
    if not has_key:
        print("\nâŒ æµ‹è¯•ç»ˆæ­¢: æœªé…ç½®APIå¯†é’¥")
        if config.llm_provider == 'openai':
            print("è¯·åœ¨.envä¸­è®¾ç½®: OPENAI_API_KEY")
        elif config.llm_provider == 'deepseek':
            print("è¯·åœ¨.envä¸­è®¾ç½®: DEEPSEEK_API_KEY")
        sys.exit(1)
    
    # æµ‹è¯•APIé…ç½®
    test_api_limits()
    
    # åŠŸèƒ½æµ‹è¯•
    print("\n" + "=" * 50)
    print("ğŸ§ª åŠŸèƒ½æµ‹è¯•")
    
    translation_ok = test_translation()
    storyboard_ok = test_storyboard()
    
    # æµ‹è¯•ç»“æœ
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœ")
    
    if translation_ok and storyboard_ok:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚")
        return True
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œç½‘ç»œè¿æ¥ã€‚")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
